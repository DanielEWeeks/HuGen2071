[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HuGen2071 book",
    "section": "",
    "text": "Preface\nThis is a Quarto book created from markdown and executable code using Quarto within RStudio.\nBook web site: https://danieleweeks.github.io/HuGen2071/\nBook source code: https://github.com/DanielEWeeks/HuGen2071\nCreated by Daniel E. Weeks\nWebsite: https://www.sph.pitt.edu/directory/daniel-weeks\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "preparation.html#basic-programming-ideas",
    "href": "preparation.html#basic-programming-ideas",
    "title": "1  Preparation",
    "section": "1.1 Basic programming ideas",
    "text": "1.1 Basic programming ideas\n\n1.1.1 Introduction to Coding\nThis web page and two short videos discusses how computer programming is very similar to writing a recipe - you have to break a complex project down into precise smaller individual steps.\nhttps://subjectguides.york.ac.uk/coding/introduction"
  },
  {
    "objectID": "preparation.html#r",
    "href": "preparation.html#r",
    "title": "1  Preparation",
    "section": "1.2 R",
    "text": "1.2 R\n\n1.2.1 PhD Training Workshop: Statistics in R\nThis online book has a nice introduction to the concepts of programming, RStudio, and R\nhttps://bookdown.org/animestina/R_Manchester/\nSee Chapters 1, 2, and 3"
  },
  {
    "objectID": "preparation.html#r-and-rstudio",
    "href": "preparation.html#r-and-rstudio",
    "title": "1  Preparation",
    "section": "1.3 R and RStudio",
    "text": "1.3 R and RStudio\n\n1.3.1 R for the Rest of Us\nAcquaint or refresh yourself with R and RStudio — including installing them on your computer with this “R for the Rest of Us course” (24 min of videos + exercises):\nhttps://rfortherestofus.com/courses/getting-started/\nSlides: https://rfortherestofus.github.io/getting-started/slides/slides.html"
  },
  {
    "objectID": "preparation.html#github",
    "href": "preparation.html#github",
    "title": "1  Preparation",
    "section": "1.4 GitHub",
    "text": "1.4 GitHub\nTo introduce yourself to GitHub:\nhttps://guides.github.com/introduction/git-handbook/\nhttps://guides.github.com/activities/hello-world/"
  },
  {
    "objectID": "preparation.html#r-markdown",
    "href": "preparation.html#r-markdown",
    "title": "1  Preparation",
    "section": "1.5 R Markdown",
    "text": "1.5 R Markdown\nTo introduce yourself or refresh yourself on R Markdown:\nhttps://rmarkdown.rstudio.com/\nScroll down and click on “Get Started”, which will take you to Lesson 1:\nhttps://rmarkdown.rstudio.com/lesson-1.html"
  },
  {
    "objectID": "preparation.html#unix",
    "href": "preparation.html#unix",
    "title": "1  Preparation",
    "section": "1.6 Unix",
    "text": "1.6 Unix\nAnd finally, to introduce yourself or refresh yourself with Unix (well, Linux in this case, but close enough), try Lessons 1–11 here:\nhttps://www.webminal.org/"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code using Quarto within RStudio.\nBook web site: https://danieleweeks.github.io/HuGen2071/\nBook source code: https://github.com/DanielEWeeks/HuGen2071\nCreated by Daniel E. Weeks\nWebsite: https://www.publichealth.pitt.edu/home/directory/daniel-e-weeks"
  },
  {
    "objectID": "logistics.html#github-set-up-an-account",
    "href": "logistics.html#github-set-up-an-account",
    "title": "3  Logistics",
    "section": "3.1 GitHub: Set up an account",
    "text": "3.1 GitHub: Set up an account\nPlease go to https://github.com and set up a GitHub account.\nChoose your GitHub user name carefully, as you may end up using it later in a professional context."
  },
  {
    "objectID": "logistics.html#github-classroom",
    "href": "logistics.html#github-classroom",
    "title": "3  Logistics",
    "section": "3.2 GitHub Classroom",
    "text": "3.2 GitHub Classroom\nAs GitHub Classroom will be used to distribute course materials and to submit assignments, it would be best if you get git working on your own computer. The easiest way to do this is to install RStudio, R, and git on your computer.\nPlease follow the detailed instructions in https://github.com/jfiksel/github-classroom-for-students\nIn particular, see Step 5 re generating an ssh key so you don’t need to login every time."
  },
  {
    "objectID": "Readings.html#introduction-and-overview",
    "href": "Readings.html#introduction-and-overview",
    "title": "4  Active Learning and Readings",
    "section": "4.1 Introduction and Overview",
    "text": "4.1 Introduction and Overview\n\n4.1.1 Learning Objectives\n\nReview the syllabus\nDescribe bioinformatics\nList various type of data used in genetics\n\n\n\n4.1.2 Readings\nBarnes (2007) Chapter 1 Carey MA, Papin JA. Ten simple rules for biologists learning to program. PLoS Comput Biol. 2018;14(1):e1005871. https://doi.org/10.1371/journal.pcbi.1005871\nDudley JT, Butte AJ. A quick guide for developing effective bioinformatics programming skills. PLoS Comput Biol. 2009;5(12):e1000589. https://doi.org/10.1371/journal.pcbi.1000589"
  },
  {
    "objectID": "Readings.html#github",
    "href": "Readings.html#github",
    "title": "4  Active Learning and Readings",
    "section": "4.2 GitHub",
    "text": "4.2 GitHub\n\n4.2.1 Learning Objectives\n\nTo learn how to use GitHub\nTo learn how to use GitHub Classroom\nTo learn how to use GitHub within RStudio\n\n\n\n4.2.2 Readings\nHappy Git and GitHub for the useR. https://happygitwithr.com/\nPerez-Riverol Y, Gatto L, Wang R, et al. Ten Simple Rules for Taking Advantage of Git and GitHub. PLoS Comput Biol. 2016;12(7):e1004947. https://doi.org/10.1371/journal.pcbi.1004947"
  },
  {
    "objectID": "Readings.html#r-basics",
    "href": "Readings.html#r-basics",
    "title": "4  Active Learning and Readings",
    "section": "4.3 R: Basics",
    "text": "4.3 R: Basics\n\n4.3.1 Learning Objectives\n\nTo become familiar with the R language and concepts\nTo learn how to read and write data with R\nTo learn control flow: choices and loops\n\n\n\n4.3.2 Active Learning:\nhttps://datacarpentry.org/R-genomics/01-intro-to-R.html\n\n\n4.3.3 Readings\nBuffalo (2015) Chapter 8 ‘R Language Basics’ (Available online through PittCat+)\nRead the first four sections, up to the end of ‘Vectors, Vectorization, and Indexing’\nhttps://pitt.primo.exlibrisgroup.com/permalink/01PITT_INST/i25aoe/cdi_askewsholts_vlebooks_9781449367510\nhttps://datacarpentry.org/R-genomics/01-intro-to-R.html\nSupplementary Reading: Spector (2008) Chapters 1 & 2 (Available online through PittCat+; link in syllabus)"
  },
  {
    "objectID": "Readings.html#r-factors-dates-subscripting",
    "href": "Readings.html#r-factors-dates-subscripting",
    "title": "4  Active Learning and Readings",
    "section": "4.4 R: Factors, Dates, Subscripting",
    "text": "4.4 R: Factors, Dates, Subscripting\n\n4.4.1 Learning Objectives\n\nTo learn how to handle factors and dates with R\nTo learn how to subset data with R\nTo learn how to manipulate characters with R\n\n\n\n4.4.2 Active Learning:\nhttps://datacarpentry.org/R-ecology-lesson/02-starting-with-data.html\nSubsetting: https://swcarpentry.github.io/r-novice-gapminder/06-data-subsetting.html\n\n\n4.4.3 Readings\nBuffalo (2015) Chapter 8 ‘R Language Basics’ (Available online through PittCat+)\nRead the ‘Factors and classes in R’ subsection at the end of the ‘Vectors, Vectorization, and Indexing’ section.\nRead the ‘Exploring Data Through Slicing and Dicing: Subsetting Dataframes’ section.\nRead the ‘Working with Strings’ section.\nhttps://pitt.primo.exlibrisgroup.com/permalink/01PITT_INST/i25aoe/cdi_askewsholts_vlebooks_9781449367510\nhttps://datacarpentry.org/R-ecology-lesson/02-starting-with-data.html\nSupplementary Readings: Spector (2008) Chapters 4, 5, 6"
  },
  {
    "objectID": "Readings.html#r-character-manipulation",
    "href": "Readings.html#r-character-manipulation",
    "title": "4  Active Learning and Readings",
    "section": "4.5 R: Character Manipulation",
    "text": "4.5 R: Character Manipulation\n\n4.5.1 Learning Objectives\n\nTo learn how to handle character data in R\nTo learn how to use regular expressions in R\n\n\n\n4.5.2 Readings\nBuffalo (2015) Chapter 8 ‘R Language Basics’ (Available online through PittCat+)\nRead the ‘Working with Strings’ section (Oh, you already read this)\nhttps://pitt.primo.exlibrisgroup.com/permalink/01PITT_INST/i25aoe/cdi_askewsholts_vlebooks_9781449367510\nRead Chapter 14 “Strings” of “R for Data Science”: https://r4ds.had.co.nz/strings.html\nSupplementary Reading: Spector (2008) Chapter 7"
  },
  {
    "objectID": "Readings.html#r-loops-and-flow-control",
    "href": "Readings.html#r-loops-and-flow-control",
    "title": "4  Active Learning and Readings",
    "section": "4.6 R: Loops and Flow Control",
    "text": "4.6 R: Loops and Flow Control\n\n4.6.1 Learning Objectives\n\nTo learn how to implement loops in R\nTo learn how to control flow in R\nTo learn how to vectorize operations\n\n\n\n4.6.2 Active Learning:\nFlow control and loops: https://swcarpentry.github.io/r-novice-gapminder/07-control-flow.html\nVectorization: https://swcarpentry.github.io/r-novice-gapminder/09-vectorization.html"
  },
  {
    "objectID": "Readings.html#r-functions-and-packages-debugging-r",
    "href": "Readings.html#r-functions-and-packages-debugging-r",
    "title": "4  Active Learning and Readings",
    "section": "4.7 R: Functions and Packages, Debugging R",
    "text": "4.7 R: Functions and Packages, Debugging R\n\n4.7.1 Learning Objectives\n\nTo learn how to write R functions and packages\nTo learn how to debug R code\n\n\n\n4.7.2 Active Learning:\nhttps://swcarpentry.github.io/r-novice-gapminder/10-functions.html\n\n\n4.7.3 Readings\nFunctions Explained: https://swcarpentry.github.io/r-novice-gapminder/10-functions.html\nBuffalo (2015) Chapter 8: Read the section ‘Digression: Debugging R Code’"
  },
  {
    "objectID": "Readings.html#r-tidyverse",
    "href": "Readings.html#r-tidyverse",
    "title": "4  Active Learning and Readings",
    "section": "4.8 R: Tidyverse",
    "text": "4.8 R: Tidyverse\n\n4.8.1 Learning Objectives\n\nTo learn how to use the pipe operator\nTo learn how to use Tidyverse functions\n\n\n\n4.8.2 Active Learning:\nhttps://uomresearchit.github.io/r-day-workshop/04-dplyr/\n\n\n4.8.3 Readings\nIntroduction to the Tidyverse: Manipulating tibbles with dplyr https://uomresearchit.github.io/r-day-workshop/04-dplyr/\nSupplementary Reading: Buffalo (2015) Chapter 8: section ‘Exploring Dataframes with dplyr’"
  },
  {
    "objectID": "Readings.html#r-recoding-and-reshaping-data",
    "href": "Readings.html#r-recoding-and-reshaping-data",
    "title": "4  Active Learning and Readings",
    "section": "4.9 R: Recoding and Reshaping Data",
    "text": "4.9 R: Recoding and Reshaping Data\n\n4.9.1 Learning Objectives\n\nTo learn how to reformat and reshape data in R\n\n\n\n4.9.2 Active Learning:\nhttps://librarycarpentry.org/lc-r/03-data-cleaning-and-transformation.html\n\n\n4.9.3 Readings\nRecoding data: Pay particular attention to the ‘Recoding values’ and ‘Creating new variables’ sections\nhttps://librarycarpentry.org/lc-r/03-data-cleaning-and-transformation/index.html\nReshaping data https://sscc.wisc.edu/sscc/pubs/dwr/reshape-tidy.html\nSupplementary Reading: Spector (2008) Chapters 8 & 9"
  },
  {
    "objectID": "Readings.html#merging-data",
    "href": "Readings.html#merging-data",
    "title": "4  Active Learning and Readings",
    "section": "4.10 Merging Data",
    "text": "4.10 Merging Data\n\n4.10.1 Learning Objectives\n\nTo learn how to use the R ‘merge’ command\nTo learn how to use the R Tidyverse join commands\n\n\n\n4.10.2 Active Learning:\nhttps://mikoontz.github.io/data-carpentry-week/lesson_joins.html\n\n\n4.10.3 Readings\nhttps://mikoontz.github.io/data-carpentry-week/lesson_joins.html#practice_with_joins\nSupplementary Reading: Buffalo (2015) Chapter 8 ‘Merging and Combining Data’. Spector (2008) Chapter 9."
  },
  {
    "objectID": "Readings.html#r-traditional-graphics-advanced-graphics",
    "href": "Readings.html#r-traditional-graphics-advanced-graphics",
    "title": "4  Active Learning and Readings",
    "section": "4.11 R: Traditional Graphics & Advanced Graphics",
    "text": "4.11 R: Traditional Graphics & Advanced Graphics\n\n4.11.1 Learning Objectives\n\nTo learn the basic graphics commands of R\nTo learn the R graphing package ggplot2\n\n\n\n4.11.2 Active Learning:\nhttps://datacarpentry.org/R-ecology-lesson/04-visualization-ggplot2.html\n\n\n4.11.3 Readings\nPlotting with ggplot2 https://datacarpentry.org/R-ecology-lesson/04-visualization-ggplot2.html\nSupplementary Reading: Wickham (2009) Chapters 2 & 3"
  },
  {
    "objectID": "Readings.html#r-exploratory-data-analysis",
    "href": "Readings.html#r-exploratory-data-analysis",
    "title": "4  Active Learning and Readings",
    "section": "4.12 R: Exploratory Data Analysis",
    "text": "4.12 R: Exploratory Data Analysis\n\n4.12.1 Learning Objectives\n\nTo learn how to summarize data frames\nTo learn how to visualize missing data patterns\nTo learn how to visualize covariation\n\n\n\n4.12.2 Readings\nMissing value visualization with tidyverse in R https://towardsdatascience.com/missing-value-visualization-with-tidyverse-in-r-a9b0fefd2246\nSuggested Reading: Buffalo (2015) Chapter 8 Sections: Exploring Data Visually with ggplot2 I: Scatterplots and Densities Exploring Data Visually with ggplot2 II: Smoothing Binning Data with cut() and Bar Plots with ggplot2 Using ggplot2 Facets."
  },
  {
    "objectID": "Readings.html#r-interactive-and-dynamic-graphics",
    "href": "Readings.html#r-interactive-and-dynamic-graphics",
    "title": "4  Active Learning and Readings",
    "section": "4.13 R: Interactive and Dynamic Graphics",
    "text": "4.13 R: Interactive and Dynamic Graphics\n\n4.13.1 Learning Objectives\n\nTo learn how to use interactive and dynamic graphics to explore your data more thoroughly\nTo learn to use iPlots and Ggobi\nTo learn to use plotly\n\n\n\n4.13.2 Readings\nCreate interactive ggplot2 graphs with plotly https://www.littlemissdata.com/blog/interactiveplots\nSuggested Reading: Wickham (2009) Chapters 2 & 3"
  },
  {
    "objectID": "Readings.html#review-and-help-with-project",
    "href": "Readings.html#review-and-help-with-project",
    "title": "4  Active Learning and Readings",
    "section": "4.14 Review and Help with Project",
    "text": "4.14 Review and Help with Project"
  },
  {
    "objectID": "Readings.html#data-quality-checking-and-filters",
    "href": "Readings.html#data-quality-checking-and-filters",
    "title": "4  Active Learning and Readings",
    "section": "4.15 Data Quality Checking and Filters",
    "text": "4.15 Data Quality Checking and Filters\n\n4.15.1 Learning Objectives\n\nTo learn how to check genotype data for quality\n\n\n\n4.15.2 Readings\nAnderson CA, Pettersson FH, Clarke GM, Cardon LR, Morris AP, Zondervan KT. Data quality control in genetic case-control association studies. Nat Protoc. 2010 Sep;5(9):1564–1573. DOI: https://doi.org/10.1038/nprot.2010.116\nSuggested Reading: Laurie CC, Doheny KF, Mirel DB, Pugh EW, Bierut LJ, Bhangale T, Boehm F, Caporaso NE, Cornelis MC, Edenberg HJ, Gabriel SB, Harris EL, Hu FB, Jacobs KB, Kraft P, Landi MT, Lumley T, Manolio TA, McHugh C, Painter I, Paschall J, Rice JP, Rice KM, Zheng X, Weir BS, GENEVA Investigators. Quality control and quality assurance in genotypic data for genome-wide association studies. Genetic epidemiology. 2010 Sep;34(6):591–602. PMID: 20718045 DOI: https://doi.org/10.1002/gepi.20516"
  },
  {
    "objectID": "Readings.html#unix-basics-streams-redirection-pipe",
    "href": "Readings.html#unix-basics-streams-redirection-pipe",
    "title": "4  Active Learning and Readings",
    "section": "4.16 Unix: Basics, Streams, Redirection, & Pipe",
    "text": "4.16 Unix: Basics, Streams, Redirection, & Pipe\n\n4.16.1 Learning Objectives\n\nTo learn basic Unix commands\nTo learn how streams operate in Unix\nTo learn out to pass streamed data from program to program in Unix\n\n\n\n4.16.2 Readings\nBuffalo (2015) Chapter 3\n“Chapter 43: Redirecting Input and Output” in Unix Power Tools, 3rd Edition by Jerry Peek, Shelley Powers, Tim O’Reilly, Mike Loukides. Published by O’Reilly Media, Inc. https://pitt.primo.exlibrisgroup.com/permalink/01PITT_INST/e8h8hp/alma9998520758606236\nTerminus, a web-based game for learning and practicing basic UNIX commands https://web.mit.edu/mprat/Public/web/Terminus/Web/main.html"
  },
  {
    "objectID": "Readings.html#plink-plink-format",
    "href": "Readings.html#plink-plink-format",
    "title": "4  Active Learning and Readings",
    "section": "4.17 PLINK & PLINK Format",
    "text": "4.17 PLINK & PLINK Format\n\n4.17.1 Learning Objectives\n\nDescribe PLINK formats\nCreate PLINK datafiles\nUse PLINK to perform genetic association testing\n\n\n\n4.17.2 Readings\nMarees AT, de Kluiver H, Stringer S, Vorspan F, Curis E, Marie-Claire C, Derks EM. A tutorial on conducting genome-wide association studies: Quality control and statistical analysis. Int J Methods Psychiatr Res. 2018 Jun;27(2):e1608. PMID: 29484742 PMCID: PMC6001694 DOI: https://doi.org/10.1002/mpr.1608\nhttps://github.com/MareesAT/GWA_tutorial/"
  },
  {
    "objectID": "Readings.html#plink-advanced",
    "href": "Readings.html#plink-advanced",
    "title": "4  Active Learning and Readings",
    "section": "4.18 PLINK Advanced",
    "text": "4.18 PLINK Advanced\n\n4.18.1 Learning Objectives\n\nTo learn how to use PLINK to manipulate data files"
  },
  {
    "objectID": "Readings.html#plink-computer-lab",
    "href": "Readings.html#plink-computer-lab",
    "title": "4  Active Learning and Readings",
    "section": "4.19 PLINK Computer Lab",
    "text": "4.19 PLINK Computer Lab\n\n4.19.1 Learning Objectives\n\nTo practice using PLINK to manipulate data files"
  },
  {
    "objectID": "Readings.html#unix-interacting-with-processes-cluster-jobs-shell-scripting",
    "href": "Readings.html#unix-interacting-with-processes-cluster-jobs-shell-scripting",
    "title": "4  Active Learning and Readings",
    "section": "4.20 Unix: Interacting with Processes, Cluster Jobs, Shell Scripting",
    "text": "4.20 Unix: Interacting with Processes, Cluster Jobs, Shell Scripting\n\n4.20.1 Learning Objectives\n\nTo learn how to interact with running processes\nTo learn about the cluster and how to submit jobs there\nTo learn how to write a script that can run in Unix\n\n\n\n4.20.2 Active Learning:\nSoftware Carpentry Unix Shell intro parts 1-3 https://swcarpentry.github.io/shell-novice/\n\n\n4.20.3 Readings\nBuffalo (2015) Chapter 7 up to the start of “Sorting Plain-Text Data with Sort” section.\nSuggested Reading: Software Carpentry Unix Shell intro parts 1-3 (https://swcarpentry.github.io/shell-novice/)"
  },
  {
    "objectID": "Readings.html#unix-data-manipulation",
    "href": "Readings.html#unix-data-manipulation",
    "title": "4  Active Learning and Readings",
    "section": "4.21 Unix: Data Manipulation",
    "text": "4.21 Unix: Data Manipulation\n\n4.21.1 Learning Objectives\n\nTo learn Unix tools like sed and awk that can be used to manipulate data\n\n\n\n4.21.2 Readings\nBuffalo (2015) Chapter 7 from the “Sorting Plain-Text Data with Sort” section on."
  },
  {
    "objectID": "Readings.html#unix-pipes-parallelization",
    "href": "Readings.html#unix-pipes-parallelization",
    "title": "4  Active Learning and Readings",
    "section": "4.22 Unix: Pipes & Parallelization",
    "text": "4.22 Unix: Pipes & Parallelization\n\n4.22.1 Learning Objectives\n\nTo learn to string programs together to process data\nTo learn how to parallelize functions in Unix\n\n\n\n4.22.2 Active Learning:\nSoftware Carpentry Unix Shell intro part 4 https://swcarpentry.github.io/shell-novice/04-pipefilter.html\n\n\n4.22.3 Readings\nBuffalo (2015) Chapter 12: “Bioinformatics Shell Scripting, Writing Pipelines, and Parallelizing Tasks”"
  },
  {
    "objectID": "Readings.html#unix-scripting-control-structures-and-variables",
    "href": "Readings.html#unix-scripting-control-structures-and-variables",
    "title": "4  Active Learning and Readings",
    "section": "4.23 Unix: Scripting, Control Structures and Variables",
    "text": "4.23 Unix: Scripting, Control Structures and Variables\n\n4.23.1 Learning Objectives\n\nTo learn how to use control structures in Unix scripting\nTo learning how to use variables in Unix\n\n\n\n4.23.2 Active Learning:\nSoftware Carpentry Unix Shell intro parts 5-7 https://swcarpentry.github.io/shell-novice/\n\n\n4.23.3 Readings\nSoftware Carpentry Unix Shell intro parts 5-7 (https://swcarpentry.github.io/shell-novice/)"
  },
  {
    "objectID": "Readings.html#genetic-data-structures",
    "href": "Readings.html#genetic-data-structures",
    "title": "4  Active Learning and Readings",
    "section": "4.24 Genetic Data Structures",
    "text": "4.24 Genetic Data Structures\n\n4.24.1 Learning Objectives\n\nTo learn about what genetic data is stored and principles for storing it\n\n\n\n4.24.2 Readings\nIntroduction to PLINK (22n14-rlm-Introduction_to_PLINK.pdf, included in this lecture’s folder)\nBennett RL, Steinhaus KA, Uhrich SB, O’Sullivan CK, Resta RG, Lochner-Doyle D, Markel DS, Vincent V, Hamanishi J. Recommendations for standardized human pedigree nomenclature. J Genet Couns. 1995 Dec;4(4):267-79. https://doi.org/10.1007/BF01408073. PMID: 24234481.\nBennett RL, French KS, Resta RG, Doyle DL. Standardized human pedigree nomenclature: update and assessment of the recommendations of the National Society of Genetic Counselors. J Genet Couns. 2008 Oct;17(5):424-33. https://doi.org/10.1007/s10897-008-9169-9. Epub 2008 Sep 16. PMID: 18792771.\nBennett RL, French KS, Resta RG, Austin J. Practice resource-focused revision: Standardized pedigree nomenclature update centered on sex and gender inclusivity: A practice resource of the National Society of Genetic Counselors. J Genet Couns. 2022 Sep 15. https://doi.org/10.1002/jgc4.1621. Epub ahead of print. PMID: 36106433."
  },
  {
    "objectID": "Readings.html#vcf-bcftools-vcftools",
    "href": "Readings.html#vcf-bcftools-vcftools",
    "title": "4  Active Learning and Readings",
    "section": "4.25 VCF, bcftools, vcftools",
    "text": "4.25 VCF, bcftools, vcftools\n\n4.25.1 Learning Objectives\n\nTo learn about VCF data format\nTo learn about bcftools and vcftools for manipulating VCF files"
  },
  {
    "objectID": "Readings.html#sam-samtools",
    "href": "Readings.html#sam-samtools",
    "title": "4  Active Learning and Readings",
    "section": "4.26 SAM & samtools",
    "text": "4.26 SAM & samtools\n\n4.26.1 Learning Objectives\n\nTo learn about SAM data format for sequence data\nTo learn about samtools to manipulate SAM data files\n\n\n\n4.26.2 Readings\nBuffalo Chapter 11 “Working with Alignment Data”\nData Wrangling and Processing for Genomics https://data-lessons.github.io/wrangling-genomics/\nRelevant links: The Sequence Alignment/Map Format Specification http://samtools.github.io/hts-specs/"
  },
  {
    "objectID": "Readings.html#genetic-data-in-r-gds",
    "href": "Readings.html#genetic-data-in-r-gds",
    "title": "4  Active Learning and Readings",
    "section": "4.27 Genetic Data in R, GDS",
    "text": "4.27 Genetic Data in R, GDS\n\n4.27.1 Learning Objectives\n\nTo learn about data structures in R for storing genetic data\nTo learn about the GDS format\n\n\n\n4.27.2 Active Learning:\nhttps://uw-gac.github.io/topmed_workshop_2017/gds-format.html (Only 2.1 - Exploring a GDS file)\n\n\n4.27.3 Readings\nZheng X, Gogarten SM, Lawrence M, Stilp A, Conomos MP, Weir BS, Laurie C, Levine D. SeqArray-a storage-efficient high-performance data format for WGS variant calls. Bioinformatics. 2017 Aug 1;33(15):2251-2257. doi: 10.1093/bioinformatics/btx145. PMID: 28334390; PMCID: PMC5860110. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860110/"
  },
  {
    "objectID": "Rbasics.html#set-up-the-data-frame-a",
    "href": "Rbasics.html#set-up-the-data-frame-a",
    "title": "5  R Basics Group Exercise",
    "section": "5.1 Set up the data frame a",
    "text": "5.1 Set up the data frame a\n\na &lt;- data.frame(n = 1:4)\ndim(a)\n\n[1] 4 1\n\na\n\n  n\n1 1\n2 2\n3 3\n4 4"
  },
  {
    "objectID": "Rbasics.html#exercise-1-recycling",
    "href": "Rbasics.html#exercise-1-recycling",
    "title": "5  R Basics Group Exercise",
    "section": "5.2 Exercise 1: recycling",
    "text": "5.2 Exercise 1: recycling\nThis exercise should help answer this question: ‘In what type of situations would “recycling” be useful?’\nUse recycling to insert into the data frame a a column named rowNum1 that contains a 1 in even rows and a 2 in odd rows.\n\n\n\n\n\n\nWarning\n\n\n\nUse a Chrome browser. If the following WebR chunk is working properly, you should see an editor window below the Run code tab displaying this line of R code: (a &lt;- data.frame(n = 1:4))\n\n\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n\n\n\nTip\n\n\n\nThe R command\na$rowNum1 &lt;- NA\nwould insert a new row into the data frame a full of NA values.\n\n\n\n\n\n\n\n\nExpand to see the answer\n\n\n\n\n\n\na$rowNum1 &lt;- c(1,2)\na\n\n  n rowNum1\n1 1       1\n2 2       2\n3 3       1\n4 4       2"
  },
  {
    "objectID": "Rbasics.html#exercise-2-vector-addition",
    "href": "Rbasics.html#exercise-2-vector-addition",
    "title": "5  R Basics Group Exercise",
    "section": "5.3 Exercise 2: vector addition",
    "text": "5.3 Exercise 2: vector addition\nUse vector addition to construct a vector of length 4 that contains a 1 in even rows and a 2 in odd rows. Then insert this vector into the data frame a into a column named rowNum6.\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n\n\n\nTip\n\n\n\nWhat vector could you add to this vector so the sum is the vector (1, 2, 1, 2)?\n\nrep(1, 4)\n\n[1] 1 1 1 1\n\n\n\n\n\n\n\n\n\n\nExpand to see the answer\n\n\n\n\n\n\nr1 &lt;- rep(1, times = 4)\nr2 &lt;- rep(c(0,1), times = 2)\nr1\n\n[1] 1 1 1 1\n\nr2\n\n[1] 0 1 0 1\n\nr1 + r2\n\n[1] 1 2 1 2\n\na$rowNum6 &lt;- r1 + r2\na\n\n  n rowNum1 rowNum6\n1 1       1       1\n2 2       2       2\n3 3       1       1\n4 4       2       2"
  },
  {
    "objectID": "Rbasics.html#exercise-3-for-loops",
    "href": "Rbasics.html#exercise-3-for-loops",
    "title": "5  R Basics Group Exercise",
    "section": "5.4 Exercise 3: for loops",
    "text": "5.4 Exercise 3: for loops\nLoops allow you to repeat actions on each item from a vector of items.\nHere is an example for loop, iterating through the values of i from 1 to 3:\n\nfor (i in 1:3) {\n  print(paste(\"i =\",i))\n}\n\n[1] \"i = 1\"\n[1] \"i = 2\"\n[1] \"i = 3\"\n\n\nThis does the same thing as this repetitive code:\n\ni.vector &lt;- c(1,2,3)\ni &lt;- i.vector[1]\nprint(paste(\"i =\",i))\n\n[1] \"i = 1\"\n\ni &lt;- i.vector[2]\nprint(paste(\"i =\",i))\n\n[1] \"i = 2\"\n\ni &lt;- i.vector[3]\nprint(paste(\"i =\",i))\n\n[1] \"i = 3\"\n\n\nUse a for loop to insert into the data frame a a column named rowNum2 that contains a 1 in even rows and a 2 in odd rows.\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n\n\n\nTip\n\n\n\nThink about how as i increments from 1 to nrow(a), how could we map that sequence (e.g. 1, 2, 3, 4) to the desired sequence of 1, 2, 1, 2.\n\n\n\n\n\n\n\n\nExpand to see the answer\n\n\n\n\n\n\n# Set value that we want to iterate 1, 2, 1, 2, ...\nj &lt;- 1\n# Initialize rowNum2 to all missing values\na$rowNum2 &lt;- NA  \n# Start the for loop, looping over the number of rows in a\nfor (i in c(1:nrow(a))) {\n   # Assign value j to row i\n   a$rowNum2[i] &lt;- j\n   # Increment j\n   j &lt;- j + 1\n   # If j is greater than 2, set it back to 1\n   if (j &gt; 2) {\n     j &lt;- 1\n   }\n}\na\n\n  n rowNum1 rowNum6 rowNum2\n1 1       1       1       1\n2 2       2       2       2\n3 3       1       1       1\n4 4       2       2       2"
  },
  {
    "objectID": "Rbasics.html#exercise-4-while-loops",
    "href": "Rbasics.html#exercise-4-while-loops",
    "title": "5  R Basics Group Exercise",
    "section": "5.5 Exercise 4: while loops",
    "text": "5.5 Exercise 4: while loops\nHere’s an example while loop:\n\ni &lt;- 1\nwhile (i &lt; 4) {\n  print(paste(\"i =\",i))\n  i &lt;- i + 1\n}\n\n[1] \"i = 1\"\n[1] \"i = 2\"\n[1] \"i = 3\"\n\n\nUse a while loop to insert into the data frame a a column named rowNum3 that contains a 1 in even rows and a 2 in odd rows.\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n\n\n\nExpand to see the answer\n\n\n\n\n\n\na$rowNum3 = NA\ni &lt;- 1 #set index\nwhile(i &lt;= nrow(a)){ #set conditions for while loop\n\n  if ((i %% 2)) { #if statement for when \"i\" is odd\n    a$rowNum3[i] &lt;- 1\n  }\n  else #else statement for when \"i\" is even\n    a$rowNum3[i] &lt;- 2\n  \n  i &lt;- i + 1 #counter for \"i\", increments by 1 with each loop iteration\n} \na\n\n  n rowNum1 rowNum6 rowNum2 rowNum3\n1 1       1       1       1       1\n2 2       2       2       2       2\n3 3       1       1       1       1\n4 4       2       2       2       2"
  },
  {
    "objectID": "Rbasics.html#exercise-5-repeat-loops",
    "href": "Rbasics.html#exercise-5-repeat-loops",
    "title": "5  R Basics Group Exercise",
    "section": "5.6 Exercise 5: repeat loops",
    "text": "5.6 Exercise 5: repeat loops\nHere’s an example repeat loop:\n\ni &lt;- 1\nrepeat {\n  print(paste(\"i =\",i))\n  i &lt;- i + 1\n  if (i &gt; 3) break\n}\n\n[1] \"i = 1\"\n[1] \"i = 2\"\n[1] \"i = 3\"\n\n\nUse a repeat loop to insert into the data frame a a column named rowNum4 that contains a 1 in even rows and a 2 in odd rows.\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n\n\n\nExpand to see the answer\n\n\n\n\n\n\na$rowNum4 &lt;- NA\ni &lt;- 1 #set index\nrepeat { \n\n  if ((i %% 2)) { #if statement for when \"i\" is odd\n    a$rowNum4[i] &lt;- 1\n  }\n  else #else statement for when \"i\" is even\n    a$rowNum4[i] &lt;- 2\n  \n  i &lt;- i + 1 #counter for \"i\", increments by 1 with each loop iteration\n  if (i &gt; nrow(a)) {\n    break\n  }\n} \na\n\n  n rowNum1 rowNum6 rowNum2 rowNum3 rowNum4\n1 1       1       1       1       1       1\n2 2       2       2       2       2       2\n3 3       1       1       1       1       1\n4 4       2       2       2       2       2"
  },
  {
    "objectID": "Rbasics.html#exercise-6-using-the-rep-function",
    "href": "Rbasics.html#exercise-6-using-the-rep-function",
    "title": "5  R Basics Group Exercise",
    "section": "5.7 Exercise 6: using the rep function",
    "text": "5.7 Exercise 6: using the rep function\nUse the rep command to insert into the data frame a a column named rowNum5 that contains a 1 in even rows and a 2 in odd rows.\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n\n\n\nExpand to see the answer\n\n\n\n\n\n\n# This will only work correctly if nrow(a) is even\na$rowNum5 &lt;- rep(c(1,2), nrow(a)/2)\na\n\n  n rowNum1 rowNum6 rowNum2 rowNum3 rowNum4 rowNum5\n1 1       1       1       1       1       1       1\n2 2       2       2       2       2       2       2\n3 3       1       1       1       1       1       1\n4 4       2       2       2       2       2       2"
  },
  {
    "objectID": "Rbasics.html#exercise-7",
    "href": "Rbasics.html#exercise-7",
    "title": "5  R Basics Group Exercise",
    "section": "5.8 Exercise 7",
    "text": "5.8 Exercise 7\nList all even rows of the data frame a.\nList rows 3 and 4 of the data frame a.\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n\n\n\nExpand to see the answer\n\n\n\n\n\n\n# All even rows\na[a$rowNum1==2,]\n\n  n rowNum1 rowNum6 rowNum2 rowNum3 rowNum4 rowNum5\n2 2       2       2       2       2       2       2\n4 4       2       2       2       2       2       2\n\n# All odd rows\na[a$rowNum1==1,]\n\n  n rowNum1 rowNum6 rowNum2 rowNum3 rowNum4 rowNum5\n1 1       1       1       1       1       1       1\n3 3       1       1       1       1       1       1"
  },
  {
    "objectID": "Rbasics.html#exercise-8",
    "href": "Rbasics.html#exercise-8",
    "title": "5  R Basics Group Exercise",
    "section": "5.9 Exercise 8",
    "text": "5.9 Exercise 8\n\n\n\n\n\n\nNote\n\n\n\nLearning objective: Learn how to alter the options of an R command to achieve your goals.\n\n\nThis exercise should help answer this question: “When reading a file, will missing data be automatically represented as NA values, or does that need to be coded/manually curated?”\nThe tab-delimited file in testdata.txt contains the following data:\n1       1       1\n2       2       2\n3       NA      99\n4       4       4\nYour collaborator who gave you these data informed you that in this file 99 stands for a missing value, as does NA.\nHowever if we use the read.table command with its default options to read this in, we fail to accomplish the desired task, as 99 is not reading as a missing value:\n\ninfile &lt;- \"data/testdata.txt\"\n# Adjust the read.table options to read the file correctly as desired.\nb &lt;- read.table(infile)\nb\n\n  V1 V2 V3\n1  1  1  1\n2  2  2  2\n3  3 NA 99\n4  4  4  4\n\nstr(b)\n\n'data.frame':   4 obs. of  3 variables:\n $ V1: int  1 2 3 4\n $ V2: int  1 2 NA 4\n $ V3: int  1 2 99 4\n\n\nUse the read.table command to read this file in while automatically setting both the ’NA” and the 99 to NA. This can be done by adjusting the various options of the read.table command.\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n\n\n\nTip\n\n\n\nRead the help page for the read.table command\n\n\n\n\n\n\n\n\nExpand to see the answer\n\n\n\n\n\nTo read this in properly, we have to let ‘read.table’ know that there is no header and that which values should be mapped to the missing NA value:\n\nb &lt;- read.table(infile, header = FALSE, na.strings = c(\"NA\",\"99\"))\nb\n\n  V1 V2 V3\n1  1  1  1\n2  2  2  2\n3  3 NA NA\n4  4  4  4\n\nstr(b)\n\n'data.frame':   4 obs. of  3 variables:\n $ V1: int  1 2 3 4\n $ V2: int  1 2 NA 4\n $ V3: int  1 2 NA 4\n\nsummary(b)\n\n       V1             V2              V3       \n Min.   :1.00   Min.   :1.000   Min.   :1.000  \n 1st Qu.:1.75   1st Qu.:1.500   1st Qu.:1.500  \n Median :2.50   Median :2.000   Median :2.000  \n Mean   :2.50   Mean   :2.333   Mean   :2.333  \n 3rd Qu.:3.25   3rd Qu.:3.000   3rd Qu.:3.000  \n Max.   :4.00   Max.   :4.000   Max.   :4.000  \n                NA's   :1       NA's   :1"
  },
  {
    "objectID": "R_char_exer.html#load-libraries",
    "href": "R_char_exer.html#load-libraries",
    "title": "6  R Character Exercise",
    "section": "6.1 Load Libraries",
    "text": "6.1 Load Libraries\n\nlibrary(tidyverse)\n# library(tidylog)\nlibrary(knitr)"
  },
  {
    "objectID": "R_char_exer.html#useful-rstudio-cheatsheet",
    "href": "R_char_exer.html#useful-rstudio-cheatsheet",
    "title": "6  R Character Exercise",
    "section": "6.2 Useful RStudio cheatsheet",
    "text": "6.2 Useful RStudio cheatsheet\nSee the “String manipulation with stringr cheatsheet” at\nhttps://www.rstudio.com/resources/cheatsheets/"
  },
  {
    "objectID": "R_char_exer.html#scenario-1",
    "href": "R_char_exer.html#scenario-1",
    "title": "6  R Character Exercise",
    "section": "6.3 Scenario 1",
    "text": "6.3 Scenario 1\nYou are working with three different sets of collaborators: 1) the clinical group that did the field work and generated the anthropometric measurements; 2) the medical laboratory that measured blood pressure in a controlled environment; and 3) the molecular laboratory that generated the genotypes.\n\nclin &lt;- read.table(file = \"data/clinical_data.txt\", header=TRUE)\nkable(clin)\n\n\n\n\nID\nheight\n\n\n\n\n1\n152\n\n\n104\n172\n\n\n2112\n180\n\n\n2543\n163\n\n\n\n\nlab &lt;- read.table(file = \"data/lab_data.txt\", header = TRUE)\nkable(lab)\n\n\n\n\nID\nSBP\n\n\n\n\nSG0001\n120\n\n\nSG0104\n111\n\n\nSG2112\n125\n\n\nSG2543\n119\n\n\n\n\ngeno &lt;- read.table(file = \"data/genotype_data.txt\", header = TRUE)\nkable(geno)\n\n\n\n\nSample\nrs1212\n\n\n\n\nTaqMan-SG0001-190601\nG/C\n\n\nTaqMan-SG0104-190602\nG/G\n\n\nTaqMan-SG2112-190603\nC/C\n\n\nTaqMan-Sg2543-190603\nC/G"
  },
  {
    "objectID": "R_char_exer.html#discussion-questions",
    "href": "R_char_exer.html#discussion-questions",
    "title": "6  R Character Exercise",
    "section": "6.4 Discussion Questions",
    "text": "6.4 Discussion Questions\n\n6.4.1 Question 1\nThe clinical group, which measured height, used integer IDs, but the medical group, which measured the blood pressure, decided to prefix the integer IDs with the string ‘SG’ (so as to distinguish them from other studies that were also using integer IDs). So ID ‘1’ was mapped to ID ‘SG0001’.\n\n\n\nThe clin data frame\n\n\nID\nheight\n\n\n\n\n1\n152\n\n\n104\n172\n\n\n2112\n180\n\n\n2543\n163\n\n\n\n\n\nDiscuss how, using R commands, you would reformat the integer IDs to be in the format “SGXXXX”. Write down your ideas in the next section, and, if you have time, try them out within an R chunk.\nHint: Use the formatC function.\n\n6.4.1.1 Interactive WebR chunk\nYou can interactively run R within this WebR chunk by clicking the Run code tab. Note that this is a limited version of R which runs within your web browser.\n\n\n\n\n\n\nNote\n\n\n\nThis Run code WebR chunk needs to be run first, before the later ones, as it downloads and reads in the required data files. The WebR chunks should be run in order, as you encounter them, from beginning to end.\n\n\nLoading\n  webR...\n\n\n  \n\n\n\n\n\n6.4.2 Answer 1\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nclin$SUBJECT_ID &lt;- paste0(\"SG\", formatC(clin$ID, width = 4, flag = \"0000\"))\nkable(clin)\n\n\n\n\nID\nheight\nSUBJECT_ID\n\n\n\n\n1\n152\nSG0001\n\n\n104\n172\nSG0104\n\n\n2112\n180\nSG2112\n\n\n2543\n163\nSG2543\n\n\n\n\n\n\n\n\n\n\n6.4.3 Question 2\nDiscuss how, using R commands, you would reformat the “SGXXXX” IDs to be integer IDs. Write down your ideas in the next section, and, if you have time, try them out within an R chunk.\n\n\n\nThe lab data frame\n\n\nID\nSBP\n\n\n\n\nSG0001\n120\n\n\nSG0104\n111\n\n\nSG2112\n125\n\n\nSG2543\n119\n\n\n\n\n\nHint: Use either the gsub command or the str_replace_all command from the stringr package.\n\n\n\n\n\n\nWarning\n\n\n\nTo read in and load the data within the WebR environment, be sure to run all of the WebR chunks in order. For example, to usefully run R code in this WebR chunk here, you first need to run the WebR chunk above in Question 1.\n\n\nLoading\n  webR...\n\n\n  \n\n\n\n\n6.4.4 Answer 2\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nlab$ID2 &lt;- as.numeric(gsub(\"SG\",\"\",lab$ID))\nkable(lab)\n\n\n\n\nID\nSBP\nID2\n\n\n\n\nSG0001\n120\n1\n\n\nSG0104\n111\n104\n\n\nSG2112\n125\n2112\n\n\nSG2543\n119\n2543\n\n\n\n\n\n\nlab$ID2 &lt;- NA\nlab$ID2 &lt;- str_replace_all(lab$ID, pattern = \"SG\", replacement = \"\") %&gt;% as.numeric()\nkable(lab)\n\n\n\n\nID\nSBP\nID2\n\n\n\n\nSG0001\n120\n1\n\n\nSG0104\n111\n104\n\n\nSG2112\n125\n2112\n\n\nSG2543\n119\n2543\n\n\n\n\n\n\n\n\n\n\n6.4.5 Question 3\nThe genotype group used IDs in the style “TaqMan-SG0001-190601”, where the first string is “TaqMan” and the ending string is the date of the genotyping experiment.\nDiscuss how, using R commands, you would extract an “SGXXXX” style ID from the “TaqMan-SG0001-190601” style IDs. Write down your ideas in the next section, and, if you have time, try them out within an R chunk.\nNote that one of the IDs has a lower case ‘g’ in it - how would you correct this, using R commands?\n\n\n\nThe geno data frame\n\n\nSample\nrs1212\n\n\n\n\nTaqMan-SG0001-190601\nG/C\n\n\nTaqMan-SG0104-190602\nG/G\n\n\nTaqMan-SG2112-190603\nC/C\n\n\nTaqMan-Sg2543-190603\nC/G\n\n\n\n\n\nHint: Use either the str_split_fixed function from the stringr package or the separate function from the tidyr package.\nLoading\n  webR...\n\n\n  \n\n\n\n\n6.4.6 Answer 3\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\na &lt;- str_split_fixed(geno$Sample, pattern = \"-\",n=3)\na\n\n     [,1]     [,2]     [,3]    \n[1,] \"TaqMan\" \"SG0001\" \"190601\"\n[2,] \"TaqMan\" \"SG0104\" \"190602\"\n[3,] \"TaqMan\" \"SG2112\" \"190603\"\n[4,] \"TaqMan\" \"Sg2543\" \"190603\"\n\ngeno$ID &lt;- toupper(a[,2])\nkable(geno)\n\n\n\n\nSample\nrs1212\nID\n\n\n\n\nTaqMan-SG0001-190601\nG/C\nSG0001\n\n\nTaqMan-SG0104-190602\nG/G\nSG0104\n\n\nTaqMan-SG2112-190603\nC/C\nSG2112\n\n\nTaqMan-Sg2543-190603\nC/G\nSG2543\n\n\n\n\n\nThe separate function from the tidyr package is also useful:\n\ngeno %&gt;% separate(Sample, into=c(\"Tech\",\"ID\",\"Suffix\"), sep=\"-\")\n\n    Tech     ID Suffix rs1212\n1 TaqMan SG0001 190601    G/C\n2 TaqMan SG0104 190602    G/G\n3 TaqMan SG2112 190603    C/C\n4 TaqMan Sg2543 190603    C/G"
  },
  {
    "objectID": "R_char_exer.html#scenario-2",
    "href": "R_char_exer.html#scenario-2",
    "title": "6  R Character Exercise",
    "section": "6.5 Scenario 2",
    "text": "6.5 Scenario 2\nA replication sample has been measured, and that is using IDs in the style “RP5XXX”.\n\njoint &lt;- read.table(file = \"data/joint_data.txt\", header = TRUE)\nkable(joint)\n\n\n\n\nID\nSBP\n\n\n\n\nSG0001\n120\n\n\nSG0104\n111\n\n\nSG2112\n125\n\n\nSG2543\n119\n\n\nRP5002\n121\n\n\nRP5012\n118\n\n\nRP5113\n112\n\n\nRP5213\n142\n\n\n\n\n\n\n6.5.1 Question 4\nDiscuss how you would use R commands to split the ‘joint’ data frame into an ‘SG’ and ‘RP’ specific piece? Write down your ideas in the next section, and, if you have time, try them out within an R chunk.\n\n\n\nThe joint data frame\n\n\nID\nSBP\n\n\n\n\nSG0001\n120\n\n\nSG0104\n111\n\n\nSG2112\n125\n\n\nSG2543\n119\n\n\nRP5002\n121\n\n\nRP5012\n118\n\n\nRP5113\n112\n\n\nRP5213\n142\n\n\n\n\n\nLoading\n  webR...\n\n\n  \n\n\n\n\n6.5.2 Answer 4\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\ngrep(pattern = \"SG\",joint$ID)\n\n[1] 1 2 3 4\n\ngrep(pattern = \"RP\", joint$ID)\n\n[1] 5 6 7 8\n\njoint.SG &lt;- joint[grep(pattern = \"SG\",joint$ID), ]\njoint.RP &lt;- joint[grep(pattern = \"RP\", joint$ID), ]\nkable(joint.SG)\n\n\n\n\nID\nSBP\n\n\n\n\nSG0001\n120\n\n\nSG0104\n111\n\n\nSG2112\n125\n\n\nSG2543\n119\n\n\n\n\nkable(joint.RP)\n\n\n\n\n\nID\nSBP\n\n\n\n\n5\nRP5002\n121\n\n\n6\nRP5012\n118\n\n\n7\nRP5113\n112\n\n\n8\nRP5213\n142\n\n\n\n\n# Reset row names\nrownames(joint.RP) &lt;- NULL\nkable(joint.RP)\n\n\n\n\nID\nSBP\n\n\n\n\nRP5002\n121\n\n\nRP5012\n118\n\n\nRP5113\n112\n\n\nRP5213\n142"
  },
  {
    "objectID": "R_Functions.html#load-libraries",
    "href": "R_Functions.html#load-libraries",
    "title": "7  R Functions Excercise",
    "section": "7.1 Load Libraries",
    "text": "7.1 Load Libraries\n\n library(tidyverse)\n# library(tidylog)"
  },
  {
    "objectID": "R_Functions.html#location",
    "href": "R_Functions.html#location",
    "title": "7  R Functions Excercise",
    "section": "7.2 Location",
    "text": "7.2 Location\nThis file exercise1_solution.Qmd is in the “HuGen2071_book” sub-folder of the “hugen2071” folder of our Lectures repository.\n\npaste0(basename(dirname(getwd())),\"/\",basename(getwd()))\n\n[1] \"hugen2071/HuGen2071_book\""
  },
  {
    "objectID": "R_Functions.html#data-set-creation-code",
    "href": "R_Functions.html#data-set-creation-code",
    "title": "7  R Functions Excercise",
    "section": "7.3 Data set creation code",
    "text": "7.3 Data set creation code\ni &lt;- 6\nfor (i in 1:10) {\nfl &lt;- data.frame(name=rep(paste0(\"name\",i),26))\nb &lt;- data.frame(name = rep(NA, 26))\nb$name &lt;- paste0(fl$name,\"_\",letters)\nb$trait &lt;- rnorm(26)\nwrite_tsv(b,paste0(\"data/dataset\",i,\".txt\"))\n}"
  },
  {
    "objectID": "R_Functions.html#example",
    "href": "R_Functions.html#example",
    "title": "7  R Functions Excercise",
    "section": "7.4 Example",
    "text": "7.4 Example\nHere we have been sent three data sets in the files that contain the trait quantitative values for each person in the data set:\n“dataset1.txt” “dataset2.txt” “dataset3.txt”\nAnd we’ve been asked to make a table that gives, for each dataset, the sample size (N), the mean of the trait, the median, and the variance.\nWe could do this by reading in each data set, one by one, as follows:\n\nresults &lt;- data.frame(dataset=rep(NA,3),N=NA, mean=NA, median=NA, var=NA)\nfl1 &lt;- read.table(\"data/dataset1.txt\",sep=\"\\t\",header=TRUE)\nresults$dataset[1] &lt;- \"dataset1\"\nresults$N &lt;- nrow(fl1)\nresults$mean[1] &lt;- mean(fl1$trait)\nresults$median[1] &lt;- median(fl1$trait)\nresults$var[1] &lt;- var(fl1$trait)\nresults\n\n   dataset  N       mean    median       var\n1 dataset1 26 0.09762111 0.2198957 0.5974116\n2     &lt;NA&gt; 26         NA        NA        NA\n3     &lt;NA&gt; 26         NA        NA        NA\n\n\n\nfl2 &lt;- read.table(\"data/dataset2.txt\",sep=\"\\t\",header=TRUE)\nresults$dataset[2] &lt;- \"dataset2\"\nresults$N &lt;- nrow(fl2)\nresults$mean[2] &lt;- mean(fl2$trait)\nresults$median[2] &lt;- median(fl2$trait)\nresults$var[2] &lt;- var(fl2$trait)\nresults\n\n   dataset  N       mean    median       var\n1 dataset1 26 0.09762111 0.2198957 0.5974116\n2 dataset2 26 0.43486401 0.3558736 1.0936651\n3     &lt;NA&gt; 26         NA        NA        NA\n\n\n\nfl3 &lt;- read.table(\"data/dataset3.txt\",sep=\"\\t\",header=TRUE)\nresults$dataset[3] &lt;- \"dataset3\"\nresults$N &lt;- nrow(fl3)\nresults$mean[3] &lt;- mean(fl3$trait)\nresults$median[3] &lt;- median(fl3$trait)\nresults$var[3] &lt;- var(fl3$trait)\nresults\n\n   dataset  N       mean    median       var\n1 dataset1 26 0.09762111 0.2198957 0.5974116\n2 dataset2 26 0.43486401 0.3558736 1.0936651\n3 dataset3 26 0.07508335 0.0445614 0.7950574\n\n\nYour colleague initially sent you the three data sets above, but now your colleague has sent you three more data sets and asked you to update the ‘results’ table.\nAs you can see, the code above is very repetitive. So let’s automate this by writing a function that loops through a list of data set files named “dataset1.txt”, “dataset2.txt”, “dataset3.txt”, etc., building up the results table as above.\n\n7.4.1 Question: How could we construct a list of file names?\nHow could we construct a list of file names?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\nHint: the list.files command provides a handy way to get a list of the input files:\n\nfls &lt;- list.files(path=\"data\",pattern=\"dataset*\")\nfls\n\n[1] \"dataset1.txt\" \"dataset2.txt\" \"dataset3.txt\" \"dataset4.txt\" \"dataset5.txt\"\n[6] \"dataset6.txt\"\n\n\n\n\n\n\n\n7.4.2 Question: Outline a possible algorithm\nOutline a possible algorithm that loops through a list of input data set files named “dataset1.txt”, “dataset2.txt”, “dataset3.txt”, etc., building up the results table as above.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nRead in the input file names into a list\nSet up an empty results table\nFor each file in our file name list\n\nRead the file\nCompute the statistics\nInsert the information into the results table\nReturn the filled-in results table\n\n\n\n\n\n\n\n7.4.3 Question: Construct a more detailed step-by-step algorithm.\nConstruct a more detailed step-by-step algorithm.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nInput the path to the folder containing the data files\nRead in the input file names into a list fls\nCount the number of input files N\nSet up an empty results table with N rows\nFor each file in our file name list fls\n\nRead the file\nCompute the statistics\nInsert the information into the correct row of the results table\n\nReturn the filled-in results table\n\n\n\n\n\n\n7.4.4 Task: Write a read_data_file function.\nWrite a read_data_file function to accomplish the required steps for a single input data file.\n\nMake the number in the data file name an argument.\n\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\nHere we make the number in the data file name an argument\n\nresults &lt;- data.frame(dataset=rep(NA,6),N=NA, mean=NA, median=NA, var=NA)\nread_data_file &lt;- function(n=1, results) {\n  fl1 &lt;- read.table(paste0(\"data/dataset\",n,\".txt\"),sep=\"\\t\",header=TRUE)\n  results$dataset[n] &lt;- paste0(\"dataset\",n,\".txt\")\n  results$N &lt;- nrow(fl1)\n  results$mean[n] &lt;- mean(fl1$trait)\n  results$median[n] &lt;- median(fl1$trait)\n  results$var[n] &lt;- var(fl1$trait)\n  invisible(results)\n}\n\n\n\n\n\nMake the path to the input file an argument to your read_data_file function.\n\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\nHere we make the path to the input file an argument.\n\nread_data_file_v2 &lt;- function(flnm, results) {\n  fl1 &lt;- read.table(paste0(\"data/\",flnm),sep=\"\\t\",header=TRUE)\n  results$dataset[n] &lt;- flnm\n  results$N &lt;- nrow(fl1)\n  results$mean[n] &lt;- mean(fl1$trait)\n  results$median[n] &lt;- median(fl1$trait)\n  results$var[n] &lt;- var(fl1$trait)\n  invisible(results)\n}\n\n\n\n\n\n\n7.4.5 Question: What does the above code assume?\nWhat does the above code assume?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\nAssumes a file naming style of ’dataset*.txt’ where the asterisk represents 1, 2, 3, …\nAssumes the files are in the “data” folder.\n\n\n\n\n\n7.4.6 Question: Extend your function to process all of the files\nThe above function read_data_file processes one file at a time. How would you write a function to loop this over to process all of our files?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nfls &lt;- list.files(path=\"data\",pattern=\"dataset*\")\n\nloop_over_dataset &lt;- function(fls) {\n  # Input: the list of file names\n  # Output: the 'results table\n  # Count the number of data set file names in fls\n  n_datasets &lt;- length(fls)\n  # Set up a results dataframe with n_datasets rows\n  results &lt;- data.frame(dataset=rep(NA,n_datasets),N=NA, mean=NA, median=NA, var=NA)\n  for (n in 1:n_datasets) {\n    results &lt;- read_data_file(n=n, results=results)\n  }\n  return(results)\n}\n\n\nloop_over_dataset(fls = fls)\n\n       dataset  N        mean      median       var\n1 dataset1.txt 26  0.09762111  0.21989574 0.5974116\n2 dataset2.txt 26  0.43486401  0.35587359 1.0936651\n3 dataset3.txt 26  0.07508335  0.04456140 0.7950574\n4 dataset4.txt 26  0.06259720  0.04813915 0.9186042\n5 dataset5.txt 26 -0.09288522 -0.19155759 0.9978161\n6 dataset6.txt 26 -0.20266667 -0.23845426 1.5605823\n\n\n\n\n\n\n\n7.4.7 Bonus question\nCan you find a subtle mistake in the read_data_file function?\nresults &lt;- data.frame(dataset=rep(NA,6),N=NA, mean=NA, median=NA, var=NA)\nread_data_file &lt;- function(n=1, results) {\n  fl1 &lt;- read.table(paste0(\"data/dataset\",n,\".txt\"),sep=\"\\t\",header=TRUE)\n  results$dataset[n] &lt;- paste0(\"dataset\",n,\".txt\")\n  results$N &lt;- nrow(fl1)\n  results$mean[n] &lt;- mean(fl1$trait)\n  results$median[n] &lt;- median(fl1$trait)\n  results$var[n] &lt;- var(fl1$trait)\n  invisible(results)\n}\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\nIf N varies across the data sets, then this line will not do the right thing:\nresults$N &lt;- nrow(fl1)\n\nresults &lt;- data.frame(dataset=rep(NA,6),N=NA, mean=NA, median=NA, var=NA)\nread_data_file &lt;- function(n=1, results) {\n  fl1 &lt;- read.table(paste0(\"data/dataset\",n,\".txt\"),sep=\"\\t\",header=TRUE)\n  results$dataset[n] &lt;- paste0(\"dataset\",n,\".txt\")\n  results$N[n] &lt;- nrow(fl1)\n  results$mean[n] &lt;- mean(fl1$trait)\n  results$median[n] &lt;- median(fl1$trait)\n  results$var[n] &lt;- var(fl1$trait)\n  invisible(results)\n}"
  },
  {
    "objectID": "exercise_tidyverse.html#load-libraries",
    "href": "exercise_tidyverse.html#load-libraries",
    "title": "8  R Tidyverse Exercise",
    "section": "8.1 Load Libraries",
    "text": "8.1 Load Libraries\nLoad the tidyverse packages\n\n library(tidyverse)\n# library(tidylog)"
  },
  {
    "objectID": "exercise_tidyverse.html#untidy-data",
    "href": "exercise_tidyverse.html#untidy-data",
    "title": "8  R Tidyverse Exercise",
    "section": "8.2 Untidy data",
    "text": "8.2 Untidy data\nLet’s use the World Health Organization TB data set from the tidyr package\n\nwho &lt;- tidyr::who\ndim(who)\n\n[1] 7240   60\n\nhead(who[,1:6] %&gt;% filter(!is.na(new_sp_m014)))\n\n# A tibble: 6 × 6\n  country     iso2  iso3   year new_sp_m014 new_sp_m1524\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 Afghanistan AF    AFG    1997           0           10\n2 Afghanistan AF    AFG    1998          30          129\n3 Afghanistan AF    AFG    1999           8           55\n4 Afghanistan AF    AFG    2000          52          228\n5 Afghanistan AF    AFG    2001         129          379\n6 Afghanistan AF    AFG    2002          90          476\n\n\nSee the help page for who for more information about this data set.\nIn particular, note this description:\n“The data uses the original codes given by the World Health Organization. The column names for columns five through 60 are made by combining new_ to a code for method of diagnosis (rel = relapse, sn = negative pulmonary smear, sp = positive pulmonary smear, ep = extrapulmonary) to a code for gender (f = female, m = male) to a code for age group (014 = 0-14 yrs of age, 1524 = 15-24 years of age, 2534 = 25 to 34 years of age, 3544 = 35 to 44 years of age, 4554 = 45 to 54 years of age, 5564 = 55 to 64 years of age, 65 = 65 years of age or older).”\nSo new_sp_m014 represents the counts of new TB cases detected by a positive pulmonary smear in males in the 0-14 age group."
  },
  {
    "objectID": "exercise_tidyverse.html#tidy-data",
    "href": "exercise_tidyverse.html#tidy-data",
    "title": "8  R Tidyverse Exercise",
    "section": "8.3 Tidy data",
    "text": "8.3 Tidy data\nTidy data: Have each variable in a column.\nQuestion: Are these data tidy?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\nNo these data are not tidy because aspects of the data that should be variables are encoded in the name of the variables.\nThese aspects are\n\ntest type.\nsex of the subjects.\nage range of the subjects.\n\n\n\n\nQuestion: How would we make these data tidy?\nConsider this portion of the data:\n\nhead(who[,1:5] %&gt;% filter(!is.na(new_sp_m014) & new_sp_m014&gt;0), 1)\n\n# A tibble: 1 × 5\n  country     iso2  iso3   year new_sp_m014\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;       &lt;dbl&gt;\n1 Afghanistan AF    AFG    1998          30\n\n\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\nWe would replace the new_sp_m014 with the following four columns:\ntype  sex   age   n\nsp    m     014  30\nThis would place each variable in its own column."
  },
  {
    "objectID": "exercise_tidyverse.html#gather",
    "href": "exercise_tidyverse.html#gather",
    "title": "8  R Tidyverse Exercise",
    "section": "8.4 Gather",
    "text": "8.4 Gather\n\nstocks &lt;- tibble(\n  time = as.Date('2009-01-01') + 0:9,\n  X = rnorm(10, 0, 1),\n  Y = rnorm(10, 0, 2),\n  Z = rnorm(10, 0, 4)\n)\n\nhead(stocks)\n\n# A tibble: 6 × 4\n  time            X       Y      Z\n  &lt;date&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 2009-01-01  0.371  5.92   -1.72 \n2 2009-01-02  0.466  0.155   2.56 \n3 2009-01-03 -0.676 -0.761   0.905\n4 2009-01-04  0.198 -0.0338  0.771\n5 2009-01-05 -0.314 -3.19   -2.40 \n6 2009-01-06  1.80   2.14    0.291\n\nstocks %&gt;% gather(\"stock\", \"price\", -time) %&gt;% head()\n\n# A tibble: 6 × 3\n  time       stock  price\n  &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt;\n1 2009-01-01 X      0.371\n2 2009-01-02 X      0.466\n3 2009-01-03 X     -0.676\n4 2009-01-04 X      0.198\n5 2009-01-05 X     -0.314\n6 2009-01-06 X      1.80"
  },
  {
    "objectID": "exercise_tidyverse.html#pivot_longer",
    "href": "exercise_tidyverse.html#pivot_longer",
    "title": "8  R Tidyverse Exercise",
    "section": "8.5 Pivot_longer",
    "text": "8.5 Pivot_longer\n\nstocks %&gt;% pivot_longer(c(X,Y,Z), names_to= \"stock\", values_to = \"price\") %&gt;% \n  head()\n\n# A tibble: 6 × 3\n  time       stock  price\n  &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt;\n1 2009-01-01 X      0.371\n2 2009-01-01 Y      5.92 \n3 2009-01-01 Z     -1.72 \n4 2009-01-02 X      0.466\n5 2009-01-02 Y      0.155\n6 2009-01-02 Z      2.56"
  },
  {
    "objectID": "exercise_tidyverse.html#who-tb-data",
    "href": "exercise_tidyverse.html#who-tb-data",
    "title": "8  R Tidyverse Exercise",
    "section": "8.6 WHO TB data",
    "text": "8.6 WHO TB data\nQuestion: How would we convert this to tidy form?\n\nhead(who[,1:6] %&gt;% filter(!is.na(new_sp_m014)))\n\n# A tibble: 6 × 6\n  country     iso2  iso3   year new_sp_m014 new_sp_m1524\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 Afghanistan AF    AFG    1997           0           10\n2 Afghanistan AF    AFG    1998          30          129\n3 Afghanistan AF    AFG    1999           8           55\n4 Afghanistan AF    AFG    2000          52          228\n5 Afghanistan AF    AFG    2001         129          379\n6 Afghanistan AF    AFG    2002          90          476\n\n\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nwho.long &lt;- who %&gt;% pivot_longer(starts_with(\"new\"), names_to = \"demo\", values_to = \"n\") %&gt;%  filter(!is.na(n))\nhead(who.long)\n\n# A tibble: 6 × 6\n  country     iso2  iso3   year demo             n\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n1 Afghanistan AF    AFG    1997 new_sp_m014      0\n2 Afghanistan AF    AFG    1997 new_sp_m1524    10\n3 Afghanistan AF    AFG    1997 new_sp_m2534     6\n4 Afghanistan AF    AFG    1997 new_sp_m3544     3\n5 Afghanistan AF    AFG    1997 new_sp_m4554     5\n6 Afghanistan AF    AFG    1997 new_sp_m5564     2\n\n\n\n\n\nQuestion: How would we split demo into variables?\n\nhead(who.long)\n\n# A tibble: 6 × 6\n  country     iso2  iso3   year demo             n\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;\n1 Afghanistan AF    AFG    1997 new_sp_m014      0\n2 Afghanistan AF    AFG    1997 new_sp_m1524    10\n3 Afghanistan AF    AFG    1997 new_sp_m2534     6\n4 Afghanistan AF    AFG    1997 new_sp_m3544     3\n5 Afghanistan AF    AFG    1997 new_sp_m4554     5\n6 Afghanistan AF    AFG    1997 new_sp_m5564     2\n\n\nLook at the variable naming scheme:\n\nnames(who) %&gt;% grep(\"m014\",., value=TRUE)\n\n[1] \"new_sp_m014\" \"new_sn_m014\" \"new_ep_m014\" \"newrel_m014\"\n\n\nQuestion: How should we adjust the demo strings so as to be able to easily split all of them into the desired variables?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nwho.long &lt;- who.long %&gt;%  \n  mutate(demo = str_replace(demo, \"newrel\", \"new_rel\"))\ngrep(\"m014\",who.long$demo, value=TRUE) %&gt;%  unique()\n\n[1] \"new_sp_m014\"  \"new_sn_m014\"  \"new_ep_m014\"  \"new_rel_m014\"\n\n\n\n\n\nQuestion: After adjusting the demo strings, how would we then separate them into the desired variables?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nwho.long &lt;- who.long %&gt;% \n  separate(demo, into = c(\"new\", \"type\", \"sexagerange\"), sep=\"_\") %&gt;% \n  separate(sexagerange, into=c(\"sex\",\"age_range\"), sep=1) %&gt;%\n  select(-new)\nhead(who.long)\n\n# A tibble: 6 × 8\n  country     iso2  iso3   year type  sex   age_range     n\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n1 Afghanistan AF    AFG    1997 sp    m     014           0\n2 Afghanistan AF    AFG    1997 sp    m     1524         10\n3 Afghanistan AF    AFG    1997 sp    m     2534          6\n4 Afghanistan AF    AFG    1997 sp    m     3544          3\n5 Afghanistan AF    AFG    1997 sp    m     4554          5\n6 Afghanistan AF    AFG    1997 sp    m     5564          2"
  },
  {
    "objectID": "exercise_tidyverse.html#conclusion",
    "href": "exercise_tidyverse.html#conclusion",
    "title": "8  R Tidyverse Exercise",
    "section": "8.7 Conclusion",
    "text": "8.7 Conclusion\nNow our untidy data are tidy.\n\nhead(who.long)\n\n# A tibble: 6 × 8\n  country     iso2  iso3   year type  sex   age_range     n\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n1 Afghanistan AF    AFG    1997 sp    m     014           0\n2 Afghanistan AF    AFG    1997 sp    m     1524         10\n3 Afghanistan AF    AFG    1997 sp    m     2534          6\n4 Afghanistan AF    AFG    1997 sp    m     3544          3\n5 Afghanistan AF    AFG    1997 sp    m     4554          5\n6 Afghanistan AF    AFG    1997 sp    m     5564          2"
  },
  {
    "objectID": "exercise_tidyverse.html#acknowledgment",
    "href": "exercise_tidyverse.html#acknowledgment",
    "title": "8  R Tidyverse Exercise",
    "section": "8.8 Acknowledgment",
    "text": "8.8 Acknowledgment\nThis exercise was modeled, in part, on this exercise:\nhttps://people.duke.edu/~ccc14/cfar-data-workshop-2018/CFAR_R_Workshop_2018_Exercisees.html"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#load-libraries",
    "href": "recoding_reshaping_interactive.html#load-libraries",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.1 Load Libraries",
    "text": "9.1 Load Libraries\n\nlibrary(tidyverse)\n# library(tidylog)"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#project-1-data",
    "href": "recoding_reshaping_interactive.html#project-1-data",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.2 Project 1 Data",
    "text": "9.2 Project 1 Data\nIn the ds data frame we have the synthetic yet realistic data we will be using in Project 1.\nIn the dd data frame we have the corresponding data dictionary.\n\nload(\"data/exercise.RData\", verbose = TRUE)\n\nLoading objects:\n  ds\n  dd\n  DictPer\n\ndim(ds)\n\n[1] 191  24\n\nnames(ds)\n\n [1] \"sample_id\"                \"Sample_trimester\"        \n [3] \"Gestationalage_sample\"    \"subject_id\"              \n [5] \"strata\"                   \"race\"                    \n [7] \"maternal_age_delivery\"    \"case_control_status\"     \n [9] \"prepregnancy_weight\"      \"height\"                  \n[11] \"prepregnancy_BMI\"         \"gravidity\"               \n[13] \"parity\"                   \"gestationalage_delivery\" \n[15] \"average_SBP_lt20weeks\"    \"average_DBP_lt20weeks\"   \n[17] \"average_SBP_labor\"        \"average_DBP_labor\"       \n[19] \"smoke_lifetime\"           \"baby_birthweight\"        \n[21] \"baby_sex\"                 \"baby_birthweight_centile\"\n[23] \"baby_SGA\"                 \"placental_pathology\"     \n\ndim(dd)\n\n[1] 27  5\n\nnames(dd)\n\n[1] \"Original.Variable.Name\" \"R21.Variable.Name\"      \"Description\"           \n[4] \"Variable.Units\"         \"Variable.Coding\""
  },
  {
    "objectID": "recoding_reshaping_interactive.html#exercise-1",
    "href": "recoding_reshaping_interactive.html#exercise-1",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.3 Exercise 1",
    "text": "9.3 Exercise 1\nSkill: Checking for duplicated IDs\n\nds %&gt;%\n    select(subject_id, sample_id, height) %&gt;%\n    head(n = 10)\n\n   subject_id sample_id height\n1      SUBJ48   SAMP149   64.6\n2      SUBJ46   SAMP037   65.7\n3      SUBJ28   SAMP120   63.3\n4      SUBJ26   SAMP187   61.1\n5      SUBJ49   SAMP082   67.6\n6      SUBJ48   SAMP149   64.6\n7      SUBJ19   SAMP074   66.1\n8      SUBJ07   SAMP063   64.4\n9      SUBJ28   SAMP053   63.3\n10     SUBJ43   SAMP085   65.7\n\n\nCheck if there are any duplicated sample_id’s using the duplicated command.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nsum(duplicated(ds$sample_id))\n\n[1] 72\n\n\n\n\n\nConstruct a table of the number of times each sample_id is duplicated:\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\ntable(table(ds$sample_id))\n\n\n 1  2  3  4  5 \n67 35 13  2  1 \n\n# But?\nsum(duplicated(ds$sample_id))\n\n[1] 72\n\n35 + 13 * 2 + 2 * 3 + 1 * 4\n\n[1] 71\n\nsum(duplicated(ds$sample_id, incomparables = NA))\n\n[1] 71\n\n\n\ntable(table(ds$sample_id, useNA = \"always\"))\n\n\n 1  2  3  4  5 \n67 36 13  2  1 \n\n36 + 13 * 2 + 2 * 3 + 1 * 4\n\n[1] 72\n\n\n\n\n\nCheck if there are any duplicated subject_ids\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nsum(duplicated(ds$subject_id))\n\n[1] 137"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#checking-for-duplicates",
    "href": "recoding_reshaping_interactive.html#checking-for-duplicates",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.4 Checking for duplicates",
    "text": "9.4 Checking for duplicates\nHow do we return every row that contains a duplicate?\n\nf &lt;- data.frame(ID = c(1, 1, 2), c2 = c(1, 2, 3))\nf\n\n  ID c2\n1  1  1\n2  1  2\n3  2  3\n\nf[duplicated(f$ID), ]\n\n  ID c2\n2  1  2"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#counting-the-number-of-occurences-of-the-id",
    "href": "recoding_reshaping_interactive.html#counting-the-number-of-occurences-of-the-id",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.5 Counting the number of occurences of the ID",
    "text": "9.5 Counting the number of occurences of the ID\n\nf %&gt;%\n    group_by(ID) %&gt;%\n    summarise(n = n())\n\n# A tibble: 2 × 2\n     ID     n\n  &lt;dbl&gt; &lt;int&gt;\n1     1     2\n2     2     1"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#count-sample_id-duplicates",
    "href": "recoding_reshaping_interactive.html#count-sample_id-duplicates",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.6 Count sample_id duplicates",
    "text": "9.6 Count sample_id duplicates\nUsing Tidyverse commands, count how many times each sample_id occcurs in the ds data frame, reporting the counts in descending order, from highest to lowest.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nds %&gt;%\n    group_by(sample_id) %&gt;%\n    summarise(n = n()) %&gt;%\n    filter(n &gt; 1) %&gt;%\n    arrange(desc(n)) %&gt;%\n    head()\n\n# A tibble: 6 × 2\n  sample_id     n\n  &lt;chr&gt;     &lt;int&gt;\n1 SAMP100       5\n2 SAMP125       4\n3 SAMP155       4\n4 SAMP017       3\n5 SAMP048       3\n6 SAMP058       3\n\n\n\nds %&gt;%\n    group_by(sample_id) %&gt;%\n    summarise(n = n()) %&gt;%\n    filter(n &gt; 1) %&gt;%\n    arrange(desc(n)) %&gt;%\n    pull(n) %&gt;%\n    table()\n\n.\n 2  3  4  5 \n36 13  2  1"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#checking-for-duplicates-1",
    "href": "recoding_reshaping_interactive.html#checking-for-duplicates-1",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.7 Checking for duplicates",
    "text": "9.7 Checking for duplicates\nHere we list all of the rows containing a duplicated ‘ID’ value using functions from the ‘tidyverse’ package:\n\nf %&gt;%\n    group_by(ID) %&gt;%\n    filter(n() &gt; 1)\n\n# A tibble: 2 × 2\n# Groups:   ID [1]\n     ID    c2\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1     1\n2     1     2\n\n\n\n9.7.1 How to list all duplicates\nUse Tidyverse commands to list all duplicates for sample_id and for subject_id. Sort the results by the ID.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\n9.7.2 Sample ID\n\nds %&gt;%\n    group_by(sample_id) %&gt;%\n    filter(n() &gt; 1) %&gt;%\n    select(sample_id, subject_id, Sample_trimester, Gestationalage_sample) %&gt;%\n    arrange(sample_id, Sample_trimester, Gestationalage_sample) %&gt;%\n    head()\n\n# A tibble: 6 × 4\n# Groups:   sample_id [3]\n  sample_id subject_id Sample_trimester Gestationalage_sample\n  &lt;chr&gt;     &lt;chr&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;\n1 SAMP002   SUBJ20                    2                 19.3 \n2 SAMP002   SUBJ20                    2                 19.7 \n3 SAMP003   SUBJ12                    1                  8.25\n4 SAMP003   SUBJ12                    1                  8.35\n5 SAMP004   SUBJ35                    2                 20.4 \n6 SAMP004   SUBJ35                    2                 20.9 \n\n\n\n\n9.7.3 Subject ID\n\nds %&gt;%\n    group_by(subject_id) %&gt;%\n    filter(n() &gt; 1) %&gt;%\n    select(subject_id, sample_id, Sample_trimester, Gestationalage_sample) %&gt;%\n    arrange(subject_id, sample_id, Sample_trimester, Gestationalage_sample) %&gt;%\n    head(10)\n\n# A tibble: 10 × 4\n# Groups:   subject_id [2]\n   subject_id sample_id Sample_trimester Gestationalage_sample\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;                 &lt;dbl&gt;\n 1 SUBJ01     SAMP011                  1                  9.00\n 2 SUBJ01     SAMP034                  3                 39.8 \n 3 SUBJ01     SAMP034                  3                 42.1 \n 4 SUBJ01     SAMP103                  2                 19.9 \n 5 SUBJ01     SAMP103                  2                 20.0 \n 6 SUBJ01     SAMP155                  3                 40.0 \n 7 SUBJ01     SAMP155                  3                 40.5 \n 8 SUBJ01     SAMP155                  3                 40.7 \n 9 SUBJ01     SAMP155                  3                 41.6 \n10 SUBJ02     SAMP113                  3                 38.6"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#exercise-2",
    "href": "recoding_reshaping_interactive.html#exercise-2",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.8 Exercise 2",
    "text": "9.8 Exercise 2\nSkill: Reshaping data\nSelect only three columns “sample_id”, “Sample_trimester”, “Gestationalage_sample”, and then reshape from ‘long’ format to ‘wide’ format using pivot_wider, taking time as the “Sample_trimester”.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nb &lt;- ds %&gt;%\n    select(sample_id, Sample_trimester, Gestationalage_sample)\n\nb2 &lt;- b %&gt;%\n    pivot_wider(id_cols = sample_id, names_from = Sample_trimester, values_from = Gestationalage_sample)\n\nWarning: Values from `Gestationalage_sample` are not uniquely identified; output will\ncontain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} %&gt;%\n  dplyr::group_by(sample_id, Sample_trimester) %&gt;%\n  dplyr::summarise(n = dplyr::n(), .groups = \"drop\") %&gt;%\n  dplyr::filter(n &gt; 1L)\n\nhead(b2)\n\n# A tibble: 6 × 5\n  sample_id `1`       `3`       `2`       `NA`  \n  &lt;chr&gt;     &lt;list&gt;    &lt;list&gt;    &lt;list&gt;    &lt;list&gt;\n1 SAMP149   &lt;dbl [3]&gt; &lt;NULL&gt;    &lt;NULL&gt;    &lt;NULL&gt;\n2 SAMP037   &lt;dbl [2]&gt; &lt;NULL&gt;    &lt;NULL&gt;    &lt;NULL&gt;\n3 SAMP120   &lt;dbl [3]&gt; &lt;NULL&gt;    &lt;NULL&gt;    &lt;NULL&gt;\n4 SAMP187   &lt;NULL&gt;    &lt;dbl [1]&gt; &lt;NULL&gt;    &lt;NULL&gt;\n5 SAMP082   &lt;NULL&gt;    &lt;NULL&gt;    &lt;dbl [1]&gt; &lt;NULL&gt;\n6 SAMP074   &lt;NULL&gt;    &lt;NULL&gt;    &lt;dbl [3]&gt; &lt;NULL&gt;\n\n\n\n9.8.1 Comment\nView b2 via the View(b2) command in RStudio - it nicely put all the different gestational age observations into one list for each sample_id x Sample_trimester combination."
  },
  {
    "objectID": "recoding_reshaping_interactive.html#exercise-3",
    "href": "recoding_reshaping_interactive.html#exercise-3",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.9 Exercise 3",
    "text": "9.9 Exercise 3\nSkill: Aggregating data\nMake a table showing the proportion of blacks and whites that are controls and cases.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nprop.table(table(ds$case_control_status, ds$race), margin = 2)\n\n   \n            B         W     White\n  0 0.5396825 0.5156250 0.0000000\n  1 0.4603175 0.4843750 1.0000000\n\n\n\n9.9.1 Comment:\nThe margin parameter of the prop.table command has to be specified in order to get the desired answer: “1 indicates rows, 2 indicates columns.\n\nprop.table(table(ds$case_control_status, ds$race), margin = 1)\n\n   \n             B          W      White\n  0 0.67326733 0.32673267 0.00000000\n  1 0.64444444 0.34444444 0.01111111\n\n\n\nprop.table(table(ds$case_control_status, ds$race))\n\n   \n              B           W       White\n  0 0.356020942 0.172774869 0.000000000\n  1 0.303664921 0.162303665 0.005235602\n\n\n\n\n\n\nConstruct more readable tables with labels using xtabs\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n9.9.2 xtabs table with labels\n\nprop.table(xtabs(~case_control_status + race, data = ds), margin = 1)\n\n                   race\ncase_control_status          B          W      White\n                  0 0.67326733 0.32673267 0.00000000\n                  1 0.64444444 0.34444444 0.01111111\n\n\n\n\n\nCreate a count cross table using Tidyverse commands\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nds %&gt;%\n    group_by(case_control_status, race) %&gt;%\n    summarize(n = n()) %&gt;%\n    spread(race, n)\n\n`summarise()` has grouped output by 'case_control_status'. You can override\nusing the `.groups` argument.\n\n\n# A tibble: 2 × 4\n# Groups:   case_control_status [2]\n  case_control_status     B     W White\n                &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1                   0    68    33    NA\n2                   1    58    31     1\n\naddmargins(xtabs(~case_control_status + race, data = ds))\n\n                   race\ncase_control_status   B   W White Sum\n                0    68  33     0 101\n                1    58  31     1  90\n                Sum 126  64     1 191\n\n\n\n\n\nCreate a proportion cross table using Tidyverse commands\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nds %&gt;%\n    group_by(case_control_status, race) %&gt;%\n    summarize(n = n()) %&gt;%\n    mutate(prop = n/sum(n)) %&gt;%\n    select(-n) %&gt;%\n    spread(race, prop)\n\n`summarise()` has grouped output by 'case_control_status'. You can override\nusing the `.groups` argument.\n\n\n# A tibble: 2 × 4\n# Groups:   case_control_status [2]\n  case_control_status     B     W   White\n                &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1                   0 0.673 0.327 NA     \n2                   1 0.644 0.344  0.0111"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#exercise-4",
    "href": "recoding_reshaping_interactive.html#exercise-4",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.10 Exercise 4",
    "text": "9.10 Exercise 4\nSkill: Summarizing within groups\nApply the summary command to the “Gestationalage_sample” within each “Sample_trimester” group.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nf &lt;- split(ds[, \"Gestationalage_sample\"], ds$Sample_trimester)\nsapply(f, summary)\n\n                1        2        3\nMin.     4.934325 16.53800 31.44880\n1st Qu.  7.838825 18.45761 35.16305\nMedian   8.565282 19.72388 37.71093\nMean     8.616799 19.83310 37.37827\n3rd Qu.  9.193104 20.69576 39.11360\nMax.    13.026958 24.60659 42.09340\n\n# Or 'tapply' can be used:\ntapply(ds$Gestationalage_sample, ds$Sample_trimester, summary)\n\n$`1`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  4.934   7.839   8.565   8.617   9.193  13.027 \n\n$`2`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.54   18.46   19.72   19.83   20.70   24.61 \n\n$`3`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  31.45   35.16   37.71   37.38   39.11   42.09 \n\n\nNote: With split(x, f), any missing values in f are dropped together with the corresponding values of x."
  },
  {
    "objectID": "recoding_reshaping_interactive.html#exercise-5-recoding-data",
    "href": "recoding_reshaping_interactive.html#exercise-5-recoding-data",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.11 Exercise 5: Recoding data",
    "text": "9.11 Exercise 5: Recoding data\nApproach 1\n\nImplement our dictionaries using look-up tables\n\nUse a named vector.\n\n\nSkill:: Recoding IDs using a dictionary\nCreate a new subject ID column named “subjectID” where you have used the DictPer named vector to recode the original “subject_id” IDs into integer IDs.\n\nhead(DictPer)\n\nSUBJ48 SUBJ46 SUBJ28 SUBJ26 SUBJ49 SUBJ19 \n    40      2     23     38     10     27 \n\n\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\na5 &lt;- ds\na5$ID &lt;- DictPer[a5$subject_id]\na5 %&gt;%\n    select(subject_id, ID) %&gt;%\n    head\n\n  subject_id ID\n1     SUBJ48 40\n2     SUBJ46  2\n3     SUBJ28 23\n4     SUBJ26 38\n5     SUBJ49 10\n6     SUBJ48 40\n\nhead(DictPer)\n\nSUBJ48 SUBJ46 SUBJ28 SUBJ26 SUBJ49 SUBJ19 \n    40      2     23     38     10     27"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#recoding-data",
    "href": "recoding_reshaping_interactive.html#recoding-data",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.12 Recoding data",
    "text": "9.12 Recoding data\nApproach 2\n\nImplement our dictionaries using left joins\n\n\n9.12.1 Comment\nI usually prefer to use a merge command like left_join to merge in the new IDs into my data frame.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nkey &lt;- data.frame(SubjID = names(DictPer), ID = DictPer)\nhead(key)\n\n       SubjID ID\nSUBJ48 SUBJ48 40\nSUBJ46 SUBJ46  2\nSUBJ28 SUBJ28 23\nSUBJ26 SUBJ26 38\nSUBJ49 SUBJ49 10\nSUBJ19 SUBJ19 27\n\nb5 &lt;- left_join(ds, key, by = c(subject_id = \"SubjID\"))\nb5 %&gt;%\n    select(subject_id, ID) %&gt;%\n    head()\n\n  subject_id ID\n1     SUBJ48 40\n2     SUBJ46  2\n3     SUBJ28 23\n4     SUBJ26 38\n5     SUBJ49 10\n6     SUBJ48 40"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#exercise-6",
    "href": "recoding_reshaping_interactive.html#exercise-6",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.13 Exercise 6",
    "text": "9.13 Exercise 6\nSkill: Filtering rows.\nCreate a data frame tri1 containing the records for Trimester 1, and a second data frame tri2 containing the records for Trimester 2.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\ntri1 &lt;- ds %&gt;%\n    filter(Sample_trimester == 1)\ntri1 %&gt;%\n    select(subject_id, sample_id, Sample_trimester) %&gt;%\n    head()\n\n  subject_id sample_id Sample_trimester\n1     SUBJ48   SAMP149                1\n2     SUBJ46   SAMP037                1\n3     SUBJ28   SAMP120                1\n4     SUBJ48   SAMP149                1\n5     SUBJ07   SAMP063                1\n6     SUBJ28   SAMP053                1\n\ntri2 &lt;- ds %&gt;%\n    filter(Sample_trimester == 2)\ntri2 %&gt;%\n    select(subject_id, sample_id, Sample_trimester) %&gt;%\n    head()\n\n  subject_id sample_id Sample_trimester\n1     SUBJ49   SAMP082                2\n2     SUBJ19   SAMP074                2\n3     SUBJ10   SAMP121                2\n4     SUBJ22   SAMP184                2\n5     SUBJ29   SAMP100                2\n6     SUBJ19   SAMP074                2"
  },
  {
    "objectID": "recoding_reshaping_interactive.html#exercise-7",
    "href": "recoding_reshaping_interactive.html#exercise-7",
    "title": "9  R Recoding Reshaping Exercise",
    "section": "9.14 Exercise 7",
    "text": "9.14 Exercise 7\nSkill: Selecting columns\nUpdate tri1 and tri2 to only contain the three columns “sample_id”, “Sample_trimester”, “Gestationalage_sample”\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\ntri1 &lt;- tri1 %&gt;%\n    select(sample_id, Sample_trimester, Gestationalage_sample)\nhead(tri1)\n\n  sample_id Sample_trimester Gestationalage_sample\n1   SAMP149                1              8.094299\n2   SAMP037                1              7.146034\n3   SAMP120                1              7.122495\n4   SAMP149                1              8.473876\n5   SAMP063                1              7.510132\n6   SAMP053                1              7.446434\n\ntri2 &lt;- tri2 %&gt;%\n    select(sample_id, Sample_trimester, Gestationalage_sample)\nhead(tri2)\n\n  sample_id Sample_trimester Gestationalage_sample\n1   SAMP082                2              21.89337\n2   SAMP074                2              21.26259\n3   SAMP121                2              18.29106\n4   SAMP184                2              18.76825\n5   SAMP100                2              24.48074\n6   SAMP074                2              21.24652"
  },
  {
    "objectID": "merging_exercise.html#load-libraries",
    "href": "merging_exercise.html#load-libraries",
    "title": "10  R Merging Exercise",
    "section": "10.1 Load Libraries",
    "text": "10.1 Load Libraries\n\nlibrary(tidyverse)\nlibrary(tidylog)"
  },
  {
    "objectID": "merging_exercise.html#input-data",
    "href": "merging_exercise.html#input-data",
    "title": "10  R Merging Exercise",
    "section": "10.2 Input data",
    "text": "10.2 Input data\nLet’s load the synthetic simulated Project 1 data and associated data dictionary:\n\nload(\"data/project1.RData\", verbose = TRUE)\n\nLoading objects:\n  ds\n  dd"
  },
  {
    "objectID": "merging_exercise.html#select-a-subset-of-subject-level-fields",
    "href": "merging_exercise.html#select-a-subset-of-subject-level-fields",
    "title": "10  R Merging Exercise",
    "section": "10.3 Select a subset of subject-level fields",
    "text": "10.3 Select a subset of subject-level fields\nSet up a data frame ‘a’ that has these subject-level fields: “subject_id” “maternal_age_delivery” “case_control_status”\n“prepregnancy_BMI”\n\na &lt;- ds %&gt;%\n    select(\"subject_id\", \"maternal_age_delivery\", \"case_control_status\", \"prepregnancy_BMI\") %&gt;%\n    arrange(subject_id)\n\nselect: dropped 20 variables (sample_id, Sample_trimester, Gestationalage_sample, strata, race, …)\n\nhead(a, 10)\n\n   subject_id maternal_age_delivery case_control_status prepregnancy_BMI\n1      SUBJ01              20.01345                   0         45.29379\n2      SUBJ01              20.01345                   0         45.29379\n3      SUBJ01              20.01345                   0         45.29379\n4      SUBJ01              20.01345                   0         45.29379\n5      SUBJ01              20.01345                   0         45.29379\n6      SUBJ01              20.01345                   0         45.29379\n7      SUBJ01              20.01345                   0         45.29379\n8      SUBJ01              20.01345                   0         45.29379\n9      SUBJ01              20.01345                   0         45.29379\n10     SUBJ02              22.22541                   1         41.63679\n\ntail(a)\n\n    subject_id maternal_age_delivery case_control_status prepregnancy_BMI\n186     SUBJ55              23.79660                   0         30.73757\n187     SUBJ56              20.77767                   1         32.30103\n188     SUBJ56              20.77767                   1         32.30103\n189     SUBJ56              20.77767                   1         32.30103\n190     SUBJ56              20.77767                   1         32.30103\n191     SUBJ56              20.77767                   1         32.30103"
  },
  {
    "objectID": "merging_exercise.html#unique-records",
    "href": "merging_exercise.html#unique-records",
    "title": "10  R Merging Exercise",
    "section": "10.4 Unique records",
    "text": "10.4 Unique records\nThe data were given to us in a way that repeated subject-level information, once for each sample from each individual subject.\nFrom your data frame ‘a’ select only the unique records, creating data frame b.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nb &lt;- unique(a)\nhead(b)\n\n   subject_id maternal_age_delivery case_control_status prepregnancy_BMI\n1      SUBJ01              20.01345                   0         45.29379\n10     SUBJ02              22.22541                   1         41.63679\n13     SUBJ03              20.80036                   1         32.55473\n15     SUBJ04              21.94422                   0         35.09978\n19     SUBJ05              20.18760                   0         41.85877\n22     SUBJ06              25.70581                   0         38.02936\n\nb1 &lt;- a %&gt;%\n    distinct()\n\ndistinct: removed 137 rows (72%), 54 rows remaining\n\nall.equal(b, b1)\n\n[1] \"Attributes: &lt; Component \\\"row.names\\\": Mean relative difference: 0.7157633 &gt;\"\n\nall.equal(b, b1, check.attributes = FALSE)\n\n[1] TRUE\n\nhead(rownames(b))\n\n[1] \"1\"  \"10\" \"13\" \"15\" \"19\" \"22\"\n\nhead(rownames(b1))\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\"\n\n# Reset row names\nrownames(b) &lt;- NULL\nrownames(b1) &lt;- NULL\nall.equal(b, b1)\n\n[1] TRUE\n\n\n\n10.4.1 Comment\nIt is better to apply unique to the whole data frame, not just to the subject_id column, as that ensures that you are selecting whole records that are unique across all of their columns.\n\n(ex1 &lt;- data.frame(ID = c(1, 1, 1, 2), trait = c(10, 9, 9, 11)))\n\n  ID trait\n1  1    10\n2  1     9\n3  1     9\n4  2    11\n\nunique(ex1)\n\n  ID trait\n1  1    10\n2  1     9\n4  2    11\n\nex1 %&gt;%\n    distinct()\n\ndistinct: removed one row (25%), 3 rows remaining\n\n\n  ID trait\n1  1    10\n2  1     9\n3  2    11"
  },
  {
    "objectID": "merging_exercise.html#check-that-the-subject_ids-are-now-not-duplicated",
    "href": "merging_exercise.html#check-that-the-subject_ids-are-now-not-duplicated",
    "title": "10  R Merging Exercise",
    "section": "10.5 Check that the subject_id’s are now not duplicated",
    "text": "10.5 Check that the subject_id’s are now not duplicated\nAre the subject_id’s unique?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nsum(duplicated(b$subject_id))\n\n[1] 0\n\nb %&gt;%\n    group_by(subject_id) %&gt;%\n    filter(n() &gt; 1)\n\ngroup_by: one grouping variable (subject_id)\n\n\nfilter (grouped): removed all rows (100%)\n\n\n# A tibble: 0 × 4\n# Groups:   subject_id [0]\n# … with 4 variables: subject_id &lt;chr&gt;, maternal_age_delivery &lt;dbl&gt;,\n#   case_control_status &lt;dbl&gt;, prepregnancy_BMI &lt;dbl&gt;"
  },
  {
    "objectID": "merging_exercise.html#create-random-integer-ids",
    "href": "merging_exercise.html#create-random-integer-ids",
    "title": "10  R Merging Exercise",
    "section": "10.6 Create random integer IDs",
    "text": "10.6 Create random integer IDs\nCreate a new column ID containing randomly chosen integer IDs; this is necessary to de-identify the data. To do this, use the sample command, sampling integers from 1 to the number of rows in data frame b.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nset.seed(10234)\nb$ID &lt;- sample(c(1:nrow(b)), replace = FALSE)\nhead(b %&gt;%\n    select(subject_id, ID))\n\nselect: dropped 3 variables (maternal_age_delivery, case_control_status, prepregnancy_BMI)\n\n\n  subject_id ID\n1     SUBJ01  6\n2     SUBJ02  4\n3     SUBJ03 41\n4     SUBJ04 14\n5     SUBJ05 51\n6     SUBJ06 37\n\nsum(duplicated(b$ID))\n\n[1] 0"
  },
  {
    "objectID": "merging_exercise.html#merge-in-new-phenotype-information",
    "href": "merging_exercise.html#merge-in-new-phenotype-information",
    "title": "10  R Merging Exercise",
    "section": "10.7 Merge in new phenotype information",
    "text": "10.7 Merge in new phenotype information\nThe PI has sent you new trait data for your subjects.\n\nnew &lt;- read_tsv(\"data/newtrait.tsv\")\n\nRows: 54 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): subject_id\ndbl (1): trait\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(new)\n\n# A tibble: 6 × 2\n  subject_id trait\n  &lt;chr&gt;      &lt;dbl&gt;\n1 SUBJ48      130.\n2 SUBJ46      104.\n3 SUBJ28      125.\n4 SUBJ26      108.\n5 SUBJ49      129.\n6 SUBJ19      117.\n\ndim(new)\n\n[1] 54  2\n\ndim(b)\n\n[1] 54  5\n\n\nCarefully merge this in using tidyverse commands.\nIf you notice any problems with this merge, prepare a report for the PI detailing what you noticed and what you’d like to ask the PI about."
  },
  {
    "objectID": "merging_exercise.html#always-be-careful-when-merging.",
    "href": "merging_exercise.html#always-be-careful-when-merging.",
    "title": "10  R Merging Exercise",
    "section": "10.8 Always be careful when merging.",
    "text": "10.8 Always be careful when merging.\n\nAlways check for duplicated IDs before doing the merge.\nAlways check that your ID columns do not contain any missing values.\nCheck that the values in the ID columns (e.g., the keys) match.\n\nCan use an ’anti_join’ to check this.\nInconsistencies in the values of the keys can be hard to fix.\n\nAlways check the dimensions to make sure the merged object has the expected number of rows and columns.\nAlways explicitly name the keys you are merging on.\n\nIf you don’t name them, then the join command will use all variables in common across x and y."
  },
  {
    "objectID": "merging_exercise.html#merge-in-new-phenotype-information-1",
    "href": "merging_exercise.html#merge-in-new-phenotype-information-1",
    "title": "10  R Merging Exercise",
    "section": "10.9 Merge in new phenotype information",
    "text": "10.9 Merge in new phenotype information\nCarefully merge in the new data in using tidyverse commands.\nIf you notice any problems with this merge, prepare a report for the PI detailing what you noticed and what you’d like to ask the PI about.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\n# Check for duplicated IDs\nsum(duplicated(b$subject_id))\n\n[1] 0\n\nsum(duplicated(new$subject_id))\n\n[1] 1\n\n# Which one is duplicated\nnew %&gt;%\n    group_by(subject_id) %&gt;%\n    mutate(n = n()) %&gt;%\n    filter(n &gt; 1)\n\ngroup_by: one grouping variable (subject_id)\n\n\nmutate (grouped): new variable 'n' (integer) with 2 unique values and 0% NA\n\n\nfilter (grouped): removed 52 rows (96%), 2 rows remaining\n\n\n# A tibble: 2 × 3\n# Groups:   subject_id [1]\n  subject_id trait     n\n  &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;\n1 SUBJ09      115.     2\n2 SUBJ09      115.     2\n\n# Check for missing IDs\nsum(is.na(b$subject_id))\n\n[1] 0\n\nsum(is.na(new$subject_id))\n\n[1] 0\n\n# Check the dimensions\ndim(b)\n\n[1] 54  5\n\ndim(new)\n\n[1] 54  2\n\nb2 &lt;- left_join(b, new, by = \"subject_id\")\n\nleft_join: added one column (trait)\n\n\n           &gt; rows only in x    2\n\n\n           &gt; rows only in y  ( 1)\n\n\n           &gt; matched rows     53    (includes duplicates)\n\n\n           &gt;                 ====\n\n\n           &gt; rows total       55\n\nhead(b2)\n\n  subject_id maternal_age_delivery case_control_status prepregnancy_BMI ID\n1     SUBJ01              20.01345                   0         45.29379  6\n2     SUBJ02              22.22541                   1         41.63679  4\n3     SUBJ03              20.80036                   1         32.55473 41\n4     SUBJ04              21.94422                   0         35.09978 14\n5     SUBJ05              20.18760                   0         41.85877 51\n6     SUBJ06              25.70581                   0         38.02936 37\n     trait\n1 138.1346\n2 113.3822\n3 116.0071\n4 127.5887\n5 113.8754\n6 110.7376\n\ndim(b2)\n\n[1] 55  6\n\nb3 &lt;- full_join(b, new, by = \"subject_id\")\n\nfull_join: added one column (trait)\n\n\n           &gt; rows only in x    2\n\n\n           &gt; rows only in y    1\n\n\n           &gt; matched rows     53    (includes duplicates)\n\n\n           &gt;                 ====\n\n\n           &gt; rows total       56\n\ndim(b3)\n\n[1] 56  6\n\n\nanti_join() return all rows from x without a match in y.\n\nanti_join(b, new, by = \"subject_id\")\n\nanti_join: added no columns\n\n\n           &gt; rows only in x    2\n\n\n           &gt; rows only in y  ( 1)\n\n\n           &gt; matched rows    (52)\n\n\n           &gt;                 ====\n\n\n           &gt; rows total        2\n\n\n  subject_id maternal_age_delivery case_control_status prepregnancy_BMI ID\n1     SUBJ18              27.54075                   1         44.14983 18\n2     SUBJ24              21.93645                   0         31.73762  9\n\nanti_join(new, b, by = \"subject_id\")\n\nanti_join: added no columns\n\n\n           &gt; rows only in x    1\n\n\n           &gt; rows only in y  ( 2)\n\n\n           &gt; matched rows    (53)\n\n\n           &gt;                 ====\n\n\n           &gt; rows total        1\n\n\n# A tibble: 1 × 2\n  subject_id trait\n  &lt;chr&gt;      &lt;dbl&gt;\n1 SUBJ00      127."
  },
  {
    "objectID": "R_graphics_exercises.html#load-libraries",
    "href": "R_graphics_exercises.html#load-libraries",
    "title": "11  R Graphics Exercise",
    "section": "11.1 Load Libraries",
    "text": "11.1 Load Libraries\n\nlibrary(tidyverse)\nlibrary(ggforce)\n# library(tidylog)\n# Set the default font to be a bit larger:\ntheme_set(theme_gray(base_size = 18))"
  },
  {
    "objectID": "R_graphics_exercises.html#exercise-1",
    "href": "R_graphics_exercises.html#exercise-1",
    "title": "11  R Graphics Exercise",
    "section": "11.2 Exercise 1",
    "text": "11.2 Exercise 1\nRead in and set up the data set b, a cleaned version of our simulated data set:\n\na &lt;- read.csv(\"data/study1.csv\")\na$ind &lt;- seq_along(a$t)\nb &lt;- a[-c(1001:1004),]\nb$g.f &lt;- factor(b$g)\nb$geno &lt;- paste(b$all1,b$all2,sep=\"/\")\n\nUsing ggplot and data set b, plot ind vs. t, coloring by case-control status (trait). What do you observe about the data?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nggplot(data=b, aes(x=ind, y=t, color=trait)) + \n   geom_point()"
  },
  {
    "objectID": "R_graphics_exercises.html#exercise-2",
    "href": "R_graphics_exercises.html#exercise-2",
    "title": "11  R Graphics Exercise",
    "section": "11.3 Exercise 2",
    "text": "11.3 Exercise 2\nUsing ggplot, plot ind vs. t, coloring by case-control status (trait) and faceting by geno. What do you observe about the data?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nggplot(data=b, aes(x=ind, y=t, color=trait)) + \n  geom_point() + \n  facet_grid(~ geno)"
  },
  {
    "objectID": "R_graphics_exercises.html#always-plot-your-data",
    "href": "R_graphics_exercises.html#always-plot-your-data",
    "title": "11  R Graphics Exercise",
    "section": "11.4 Always plot your data",
    "text": "11.4 Always plot your data\n\nlibrary(tidyverse)\nd &lt;- read_tsv(\"data/example.tsv\")\n\nNew names:\nRows: 142 Columns: 26\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \"\\t\" dbl\n(26): x...1, y...2, x...3, y...4, x...5, y...6, x...7, y...8, x...9, y.....\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `x` -&gt; `x...1`\n• `y` -&gt; `y...2`\n• `x` -&gt; `x...3`\n• `y` -&gt; `y...4`\n• `x` -&gt; `x...5`\n• `y` -&gt; `y...6`\n• `x` -&gt; `x...7`\n• `y` -&gt; `y...8`\n• `x` -&gt; `x...9`\n• `y` -&gt; `y...10`\n• `x` -&gt; `x...11`\n• `y` -&gt; `y...12`\n• `x` -&gt; `x...13`\n• `y` -&gt; `y...14`\n• `x` -&gt; `x...15`\n• `y` -&gt; `y...16`\n• `x` -&gt; `x...17`\n• `y` -&gt; `y...18`\n• `x` -&gt; `x...19`\n• `y` -&gt; `y...20`\n• `x` -&gt; `x...21`\n• `y` -&gt; `y...22`\n• `x` -&gt; `x...23`\n• `y` -&gt; `y...24`\n• `x` -&gt; `x...25`\n• `y` -&gt; `y...26`\n\nn1 &lt;- rep(c(\"x\",\"y\"), 13)\nn2 &lt;- c(\"\",\"\",rep(\"_\",24))\nn3 &lt;- c(\"\", \"\", c(sort(rep(c(1:12), 2))))\nnames(d) &lt;- paste0(n1,n2,n3)\nnames(d)\n\n [1] \"x\"    \"y\"    \"x_1\"  \"y_1\"  \"x_2\"  \"y_2\"  \"x_3\"  \"y_3\"  \"x_4\"  \"y_4\" \n[11] \"x_5\"  \"y_5\"  \"x_6\"  \"y_6\"  \"x_7\"  \"y_7\"  \"x_8\"  \"y_8\"  \"x_9\"  \"y_9\" \n[21] \"x_10\" \"y_10\" \"x_11\" \"y_11\" \"x_12\" \"y_12\""
  },
  {
    "objectID": "R_graphics_exercises.html#similar-regression-lines",
    "href": "R_graphics_exercises.html#similar-regression-lines",
    "title": "11  R Graphics Exercise",
    "section": "11.5 Similar regression lines",
    "text": "11.5 Similar regression lines\nThese three data sets have very similar regression lines:\n\nsummary(lm(x ~ y, data=d)) %&gt;%  coef()\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept) 56.17563819 2.87986960 19.5063131 9.435087e-42\ny           -0.03991951 0.05250204 -0.7603419 4.483288e-01\n\nsummary(lm(x_1 ~ y_1, data=d)) %&gt;%  coef()\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept) 56.31108156 2.87906158 19.5588319 7.158847e-42\ny_1         -0.04269949 0.05249244 -0.8134407 4.173467e-01\n\nsummary(lm(x_3 ~ y_3, data=d)) %&gt;%  coef()\n\n               Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept) 56.18271411 2.87924135 19.5130270 9.107718e-42\ny_3         -0.04012859 0.05249468 -0.7644316 4.458966e-01\n\n\n\nggplot(d,aes(x=x,y=y)) + geom_point() +\n  geom_smooth(method=\"lm\") + ggtitle(\"Linear regression of y ~ x\")\n\n\n\n\nNow try this:\nggplot(d,aes(x=x_1,y=y_1)) + geom_point() + \n  geom_smooth(method=\"lm\")\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nggplot(d,aes(x=x_1,y=y_1)) + geom_point() + \n  geom_smooth(method=\"lm\") + ggtitle(\"Linear regression of y_1 ~ x_1\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nAnd now try this:\nggplot(d,aes(x=x_3,y=y_3)) + geom_point() + \n  geom_smooth(method=\"lm\")\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n11.5.1 Always plot your data!\n\nggplot(d,aes(x=x_3,y=y_3)) + geom_point() + \n  geom_smooth(method=\"lm\") + ggtitle(\"Linear regression of y_3 ~ x_3\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "R_graphics_exercises.html#always-plot-your-data-2",
    "href": "R_graphics_exercises.html#always-plot-your-data-2",
    "title": "11  R Graphics Exercise",
    "section": "11.6 Always plot your data",
    "text": "11.6 Always plot your data\n\nf &lt;- read_tsv(\"data/BoxPlots.tsv\")\n# Delete the first column\nf &lt;- f[,-1]\nhead(f)\n\n# A tibble: 6 × 5\n   left lines normal right split\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 -9.77 -9.77  -9.76 -9.76 -9.77\n2 -9.76 -9.74  -9.72 -9.05 -9.77\n3 -9.75 -9.77  -9.68 -8.51 -9.77\n4 -9.77 -9.77  -9.64 -8.24 -9.77\n5 -9.76 -9.77  -9.6  -8.82 -9.77\n6 -9.77 -9.76  -9.56 -8.07 -9.76\n\n\nStacking vectors concatenates multiple vectors into a single vector along with a factor indicating where each observation originated.\n\nhead(stack(f),2)\n\n     values  ind\n1 -9.769107 left\n2 -9.763145 left\n\n\nNow try this:\nggplot(stack(f), aes(x = ind, y = values)) +\n  geom_boxplot()\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n11.7 Identical box plots\nThese data have essentially identical box plots."
  },
  {
    "objectID": "R_graphics_exercises.html#identical-box-plots",
    "href": "R_graphics_exercises.html#identical-box-plots",
    "title": "11  R Graphics Exercise",
    "section": "11.7 Identical box plots",
    "text": "11.7 Identical box plots\nThese data have essentially identical box plots."
  },
  {
    "objectID": "R_graphics_exercises.html#boxplots",
    "href": "R_graphics_exercises.html#boxplots",
    "title": "11  R Graphics Exercise",
    "section": "11.8 Boxplots",
    "text": "11.8 Boxplots\nWhile the box plots are identical, box plots may not tell the whole story.\nLet’s try violin plots instead:\nggplot(stack(f), aes(x = ind, y = values)) +\n  geom_violin()\nA violin plot is a mirrored density plot.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n11.9 Non-identical violin plots"
  },
  {
    "objectID": "R_graphics_exercises.html#non-identical-violin-plots",
    "href": "R_graphics_exercises.html#non-identical-violin-plots",
    "title": "11  R Graphics Exercise",
    "section": "11.9 Non-identical violin plots",
    "text": "11.9 Non-identical violin plots"
  },
  {
    "objectID": "R_graphics_exercises.html#sina-plots",
    "href": "R_graphics_exercises.html#sina-plots",
    "title": "11  R Graphics Exercise",
    "section": "11.10 Sina plots",
    "text": "11.10 Sina plots\nSidiropoulos, N., Sohi, S.H., Rapin, N., and Bagger, F.O. (2015). SinaPlot: an enhanced chart for simple and truthful representation of single observations over multiple classes. bioRxiv 28191. https://www.biorxiv.org/content/early/2015/10/02/028191\nlibrary(ggforce)\nggplot(stack(f), aes(x = ind, y = values)) +\n   geom_violin() + geom_sina()\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n11.11 Sina plots"
  },
  {
    "objectID": "R_graphics_exercises.html#sina-plots-1",
    "href": "R_graphics_exercises.html#sina-plots-1",
    "title": "11  R Graphics Exercise",
    "section": "11.11 Sina plots",
    "text": "11.11 Sina plots"
  },
  {
    "objectID": "R_graphics_exercises.html#sina-plots-2",
    "href": "R_graphics_exercises.html#sina-plots-2",
    "title": "11  R Graphics Exercise",
    "section": "11.12 Sina plots",
    "text": "11.12 Sina plots\nmethod == \"counts\": The borders are defined by the number of samples that occupy the same bin.\nggplot(stack(f), aes(x = ind, y = values)) +\n   geom_violin() + geom_sina(method=\"count\")\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n11.13 Sina plots"
  },
  {
    "objectID": "R_graphics_exercises.html#sina-plots-3",
    "href": "R_graphics_exercises.html#sina-plots-3",
    "title": "11  R Graphics Exercise",
    "section": "11.13 Sina plots",
    "text": "11.13 Sina plots"
  },
  {
    "objectID": "R_graphics_exercises.html#drawing-multiple-graphs",
    "href": "R_graphics_exercises.html#drawing-multiple-graphs",
    "title": "11  R Graphics Exercise",
    "section": "11.14 Drawing multiple graphs",
    "text": "11.14 Drawing multiple graphs\nSometimes we’d like to draw multiple plots, looping across variables. Doing this within an R Markdown or Quarto Markdown document using ggplot2 is tricky. See https://dplyr.tidyverse.org/articles/programming.html and https://r4ds.hadley.nz/functions.html#plot-functions for details.\nHere’s one way to do this - this example code will generate two scatter plots:\n\nx.names &lt;- c(\"x\",\"x_1\")\ny.names &lt;- c(\"y\", \"y_1\")\nfor (i in 1:2) {\n  x.nam &lt;- sym(x.names[i])\n  y.nam &lt;- sym(y.names[i])\n  print(ggplot(data=d, aes(x = {{ x.nam }}, \n                           y = {{ y.nam }})) + \n          geom_point())\n}"
  },
  {
    "objectID": "R_graphics_exercises.html#writing-ggplot-functions",
    "href": "R_graphics_exercises.html#writing-ggplot-functions",
    "title": "11  R Graphics Exercise",
    "section": "11.15 Writing ggplot functions",
    "text": "11.15 Writing ggplot functions\nSee https://r4ds.hadley.nz/functions.html#plot-functions\n\nlibrary(palmerpenguins)\n\nPlDensity &lt;- function(fill, ...) {\n  ggplot(penguins %&gt;% filter(!is.na(bill_length_mm)), \n         aes(bill_length_mm, fill = {{ fill }})) +\n    geom_density(alpha = 0.5) +\n    facet_wrap(vars(...))\n}\n\nExample from: https://twitter.com/yutannihilat_en/status/1574387230025875457?s=20&t=FLbwErwEKQKWtKIGufDLIQ\n\nPlDensity(species)\n\n\n\n\n\nPlDensity(island, sex) %&gt;% print() %&gt;% suppressWarnings()\n\n\n\n\n\nPlDensity(sex, island, year) %&gt;% print() %&gt;% suppressWarnings()"
  },
  {
    "objectID": "R_graphics_exercises.html#exercise-3",
    "href": "R_graphics_exercises.html#exercise-3",
    "title": "11  R Graphics Exercise",
    "section": "11.16 Exercise 3",
    "text": "11.16 Exercise 3\nConsider this example code:\n\nhistogram &lt;- function(df, var, binwidth) {\n  df |&gt; \n    ggplot(aes({{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\nFrom: https://twitter.com/hadleywickham/status/1574373127349575680?s=20&t=FLbwErwEKQKWtKIGufDLIQ\nWhen applied to the quantitative trait t from the data frame b, this generates this histogram:\n\nhistogram(b, t, 0.1)\n\n\n\n\n\n11.16.1 Exercise\nAfter reading the example above, extend the histogram function to allow facetting and use it to draw a histogram of the quantitative trait t facetted by geno using the data set b that we set up above.\n\n\n\n\n\n\nHints\n\n\n\n\nSee https://r4ds.hadley.nz/functions.html#facetting\nUse the vars() function\n\n\n\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\nHadley Wickham states:\nYou have to use the vars() syntax\nfoo &lt;- function(x) {\n  ggplot(mtcars) +\n    aes(x = mpg, y = disp) +\n    geom_point() +\n    facet_wrap(vars({{ x }}))\n}\nTweet: https://twitter.com/hadleywickham/status/1574380137524887554?s=20&t=FLbwErwEKQKWtKIGufDLIQ\n\nhistogram &lt;- function(df, var, binwidth, grp) {\n  df |&gt; \n    ggplot(aes({{ var }})) + \n    geom_histogram(binwidth = binwidth) +\n    facet_wrap(vars({{ grp }}))\n}\n\n\nhistogram(b, t, 0.1)\n\n\n\n\n\nhistogram(b, t, 0.1, geno)"
  },
  {
    "objectID": "R_graphics_exercises.html#source-of-data",
    "href": "R_graphics_exercises.html#source-of-data",
    "title": "11  R Graphics Exercise",
    "section": "11.17 Source of data",
    "text": "11.17 Source of data\nIllustrative data sets from https://www.autodeskresearch.com/publications/samestats"
  },
  {
    "objectID": "reorder_exercise.html#load-libraries",
    "href": "reorder_exercise.html#load-libraries",
    "title": "12  R Reordering Exercise",
    "section": "12.1 Load Libraries",
    "text": "12.1 Load Libraries\n\nlibrary(tidyverse)\nlibrary(tidylog)"
  },
  {
    "objectID": "reorder_exercise.html#create-some-example-data",
    "href": "reorder_exercise.html#create-some-example-data",
    "title": "12  R Reordering Exercise",
    "section": "12.2 Create some example data",
    "text": "12.2 Create some example data\nHere we set up a data dictionary dd and some corresponding data ds. However, it is better if the order of the rows in the data dictionary dd match the order of the columns in the data ds.\n\nset.seed(1562345)\n# Set up a data dictionary\ndd &lt;- data.frame(VARNAME = sample(letters, 26), TYPE = \"numeric\")\n# Set up data\nds &lt;- as.data.frame(t(dd %&gt;%\n    arrange(VARNAME)))\nnames(ds) &lt;- letters\nrownames(ds) &lt;- NULL\nds[1, ] &lt;- rnorm(26)\nds[2, ] &lt;- runif(26)\nds$ID &lt;- c(1, 2)\nds &lt;- ds %&gt;%\n    select(ID, everything())\n\nselect: columns reordered (ID, a, b, c, d, …)\n\n# Randomly rearrange the columns\nidx &lt;- sample(letters, 26)\nidx &lt;- c(\"ID\", idx)\nds &lt;- ds %&gt;%\n    select(all_of(idx))\n\nselect: columns reordered (ID, b, z, a, p, …)\n\ndd &lt;- bind_rows(dd, data.frame(VARNAME = \"ID\", TYPE = \"string\"))\ndim(dd)\n\n[1] 27  2\n\nhead(dd)\n\n  VARNAME    TYPE\n1       c numeric\n2       m numeric\n3       f numeric\n4       e numeric\n5       a numeric\n6       d numeric\n\ndim(ds)\n\n[1]  2 27\n\nhead(ds[1:3])\n\n  ID                 b                 z\n1  1  1.02333343074042  0.47956883003516\n2  2 0.858655267162248 0.136965574463829\n\nnames(ds)\n\n [1] \"ID\" \"b\"  \"z\"  \"a\"  \"p\"  \"f\"  \"u\"  \"m\"  \"q\"  \"n\"  \"d\"  \"o\"  \"s\"  \"k\"  \"e\" \n[16] \"x\"  \"c\"  \"h\"  \"i\"  \"g\"  \"j\"  \"r\"  \"t\"  \"y\"  \"l\"  \"w\"  \"v\""
  },
  {
    "objectID": "reorder_exercise.html#task-reorder-rows-in-dd-in-the-order-of-dss-columns",
    "href": "reorder_exercise.html#task-reorder-rows-in-dd-in-the-order-of-dss-columns",
    "title": "12  R Reordering Exercise",
    "section": "12.3 Task: Reorder rows in dd in the order of ds’s columns",
    "text": "12.3 Task: Reorder rows in dd in the order of ds’s columns\n\ncolnames(ds)\n\n [1] \"ID\" \"b\"  \"z\"  \"a\"  \"p\"  \"f\"  \"u\"  \"m\"  \"q\"  \"n\"  \"d\"  \"o\"  \"s\"  \"k\"  \"e\" \n[16] \"x\"  \"c\"  \"h\"  \"i\"  \"g\"  \"j\"  \"r\"  \"t\"  \"y\"  \"l\"  \"w\"  \"v\" \n\ndd$VARNAME\n\n [1] \"c\"  \"m\"  \"f\"  \"e\"  \"a\"  \"d\"  \"v\"  \"h\"  \"k\"  \"t\"  \"p\"  \"j\"  \"l\"  \"x\"  \"w\" \n[16] \"y\"  \"b\"  \"o\"  \"s\"  \"r\"  \"i\"  \"z\"  \"u\"  \"n\"  \"g\"  \"q\"  \"ID\"\n\n\nThis assumes that every row of dd is in colnames(ds) and every colnames(ds) value is represented in dd. Perhaps that should be checked first."
  },
  {
    "objectID": "reorder_exercise.html#assumption-check-question",
    "href": "reorder_exercise.html#assumption-check-question",
    "title": "12  R Reordering Exercise",
    "section": "12.4 Assumption Check Question",
    "text": "12.4 Assumption Check Question\nHow would you check that every variable listed in the data dictionary dd is named in colnames(ds) and every colnames(ds) value is represented in the data dictionary dd?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\ntable(dd$VARNAME %in% colnames(ds))\n\n\nTRUE \n  27 \n\ntable(colnames(ds) %in% dd$VARNAME)\n\n\nTRUE \n  27 \n\n\nNote that we should also check to see if the VARNAME’s are unique and the colnames of ds are unique.\n\nsum(duplicated(dd$VARNAME))\n\n[1] 0\n\nsum(duplicated(colnames(ds)))\n\n[1] 0"
  },
  {
    "objectID": "reorder_exercise.html#task-reorder-rows-in-dd-to-match-the-order-of-the-columns-in-ds",
    "href": "reorder_exercise.html#task-reorder-rows-in-dd-to-match-the-order-of-the-columns-in-ds",
    "title": "12  R Reordering Exercise",
    "section": "12.5 Task: Reorder rows in dd to match the order of the columns in ds",
    "text": "12.5 Task: Reorder rows in dd to match the order of the columns in ds\nTask: Reorder rows in the data dictionary dd to match the order of the columns in the data ds\n\nWhat are various ways you could rearrange the rows of a data frame?\n\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\n# Assign VARNAME to be the rownames of dd\nrownames(dd) &lt;- dd$VARNAME\n# Rearrange by row names:\ndd2 &lt;- dd[colnames(ds), ]\n# Check if this worked:\nall.equal(dd2$VARNAME, colnames(ds))\n\n[1] TRUE\n\n\nWe can use match also:\n\n# match returns a vector of the positions of (first) matches of its first\n# argument in its second.\ndd3 &lt;- dd[match(colnames(ds), dd$VARNAME), ]\n# Check if this worked:\nall.equal(dd3$VARNAME, colnames(ds))\n\n[1] TRUE"
  },
  {
    "objectID": "reorder_exercise.html#question-use-arrange",
    "href": "reorder_exercise.html#question-use-arrange",
    "title": "12  R Reordering Exercise",
    "section": "12.6 Question: use arrange?",
    "text": "12.6 Question: use arrange?\nQuestion: Is there a way to do this using arrange?\n\n\n\n\n\n\nExpand to see the first attempt\n\n\n\n\n\nThis does not work, because tidyverse wants to work on columns of data within dd:\n\ndd4 &lt;- dd %&gt;%\n    arrange(colnames(ds))\n# Check if this worked:\nall.equal(dd4$VARNAME, colnames(ds))\n\n[1] \"26 string mismatches\""
  },
  {
    "objectID": "reorder_exercise.html#question-use-arrange-1",
    "href": "reorder_exercise.html#question-use-arrange-1",
    "title": "12  R Reordering Exercise",
    "section": "12.7 Question: use arrange?",
    "text": "12.7 Question: use arrange?\nQuestion: Is there a way to do this using arrange?\narrange() orders the rows of a data frame by the values of selected columns.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\ndd4 &lt;- dd %&gt;%\n    mutate(neworder = match(.$VARNAME, colnames(ds))) %&gt;%\n    arrange(neworder) %&gt;%\n    select(-neworder)\n\nmutate: new variable 'neworder' (integer) with 27 unique values and 0% NA\n\n\nselect: dropped one variable (neworder)\n\nall.equal(dd4$VARNAME, colnames(ds))\n\n[1] TRUE"
  },
  {
    "objectID": "reorder_exercise.html#question-use-slice",
    "href": "reorder_exercise.html#question-use-slice",
    "title": "12  R Reordering Exercise",
    "section": "12.8 Question: use slice",
    "text": "12.8 Question: use slice\nQuestion: Is there a way to do this using the slice command?\nslice() lets you index rows by their (integer) locations.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\ndd6 &lt;- dd %&gt;%\n    slice(match(colnames(ds), .$VARNAME))\n\nslice: no rows removed\n\nall.equal(dd6$VARNAME, colnames(ds))\n\n[1] TRUE"
  },
  {
    "objectID": "reorder_exercise.html#question-use-select",
    "href": "reorder_exercise.html#question-use-select",
    "title": "12  R Reordering Exercise",
    "section": "12.9 Question: use select?",
    "text": "12.9 Question: use select?\nQuestion: Is there a way to do this by transposing and then using select?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\n# Transpose so rows become columns, and then we can use 'select' to rearrange\n# those columns, and then transpose back, and rename columns as needed.\ndd5 &lt;- dd %&gt;%\n    t() %&gt;%\n    as_tibble(.name_repair = \"unique\") %&gt;%\n    select(colnames(ds)) %&gt;%\n    t() %&gt;%\n    as.data.frame() %&gt;%\n    rename(VARNAME = \"V1\", TYPE = \"V2\")\n\nselect: columns reordered (ID, b, z, a, p, …)\n\n\nrename: renamed 2 variables (VARNAME, TYPE)\n\nall.equal(dd5$VARNAME, colnames(ds))\n\n[1] TRUE"
  },
  {
    "objectID": "reorder_exercise.html#question-use-row-names",
    "href": "reorder_exercise.html#question-use-row-names",
    "title": "12  R Reordering Exercise",
    "section": "12.10 Question: use row names",
    "text": "12.10 Question: use row names\nQuestion: What about using row names?\n“While a tibble can have row names (e.g., when converting from a regular data frame), they are removed when subsetting with the [ operator. A warning will be raised when attempting to assign non-NULL row names to a tibble. Generally, it is best to avoid row names, because they are basically a character column with different semantics than every other column.”\nFrom: https://tibble.tidyverse.org/reference/rownames.html"
  },
  {
    "objectID": "EDA.html#load-libraries",
    "href": "EDA.html#load-libraries",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.1 Load Libraries",
    "text": "13.1 Load Libraries\n\nlibrary(tidyverse)\nlibrary(tidylog)\nlibrary(DataExplorer)\nlibrary(GGally)"
  },
  {
    "objectID": "EDA.html#explore-project-1-data",
    "href": "EDA.html#explore-project-1-data",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.2 Explore Project 1 data",
    "text": "13.2 Explore Project 1 data\nLet’s explore the Project 1 data set:\n\nload(\"data/project1.RData\", verbose = TRUE)\n\nLoading objects:\n  ds\n  dd\n\n\n\nds = data set\ndd = data dictionary"
  },
  {
    "objectID": "EDA.html#dimensions",
    "href": "EDA.html#dimensions",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.3 Dimensions",
    "text": "13.3 Dimensions\n\nWhat are the dimensions of our data?"
  },
  {
    "objectID": "EDA.html#dimensions-1",
    "href": "EDA.html#dimensions-1",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.4 Dimensions",
    "text": "13.4 Dimensions\nTask: Examine the dimensions of our data and data dictionary.\n\n13.4.1 Data ds\n\ndim(ds)\n\n[1] 191  24\n\nnames(ds)\n\n [1] \"sample_id\"                \"Sample_trimester\"        \n [3] \"Gestationalage_sample\"    \"subject_id\"              \n [5] \"strata\"                   \"race\"                    \n [7] \"maternal_age_delivery\"    \"case_control_status\"     \n [9] \"prepregnancy_weight\"      \"height\"                  \n[11] \"prepregnancy_BMI\"         \"gravidity\"               \n[13] \"parity\"                   \"gestationalage_delivery\" \n[15] \"average_SBP_lt20weeks\"    \"average_DBP_lt20weeks\"   \n[17] \"average_SBP_labor\"        \"average_DBP_labor\"       \n[19] \"smoke_lifetime\"           \"baby_birthweight\"        \n[21] \"baby_sex\"                 \"baby_birthweight_centile\"\n[23] \"baby_SGA\"                 \"placental_pathology\"     \n\n\n\n\n13.4.2 Data dictionay dd\n\ndim(dd)\n\n[1] 27  5\n\nnames(dd)\n\n[1] \"Original.Variable.Name\" \"R21.Variable.Name\"      \"Description\"           \n[4] \"Variable.Units\"         \"Variable.Coding\""
  },
  {
    "objectID": "EDA.html#arrangement",
    "href": "EDA.html#arrangement",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.5 Arrangement",
    "text": "13.5 Arrangement\n\nHow are the data arranged?\n\nIs it in tidy format?\nIs it one row per sample or per subject?\nWere subjects sampled more than once?\n\n\n\n13.5.1 Samples or subjects\nIs it one row per sample or per subject?\nQuestion: How would you figure out the answer to this question?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nsum(duplicated(ds$sample_id))\n\n[1] 72\n\nlength(unique(ds$sample_id))\n\n[1] 119\n\nlength(unique(ds$subject_id))\n\n[1] 54\n\n\n\n\n\n\n\n13.5.2 Unique values\nQuestion: How can we figure out the number of unique values in each column of our ds data frame?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nsapply(ds, function(x) {\n    length(unique(x))\n}) %&gt;%\n    kable()\n\n\n\n\n\nx\n\n\n\n\nsample_id\n119\n\n\nSample_trimester\n4\n\n\nGestationalage_sample\n189\n\n\nsubject_id\n54\n\n\nstrata\n21\n\n\nrace\n3\n\n\nmaternal_age_delivery\n54\n\n\ncase_control_status\n2\n\n\nprepregnancy_weight\n51\n\n\nheight\n42\n\n\nprepregnancy_BMI\n54\n\n\ngravidity\n5\n\n\nparity\n4\n\n\ngestationalage_delivery\n54\n\n\naverage_SBP_lt20weeks\n19\n\n\naverage_DBP_lt20weeks\n16\n\n\naverage_SBP_labor\n23\n\n\naverage_DBP_labor\n27\n\n\nsmoke_lifetime\n2\n\n\nbaby_birthweight\n30\n\n\nbaby_sex\n2\n\n\nbaby_birthweight_centile\n52\n\n\nbaby_SGA\n1\n\n\nplacental_pathology\n2\n\n\n\n\n\n\n\n\n\n\n13.5.3 Subject-level data set\nTask: Construct a subject-level data set\nHow would you construct a subject-level data set?\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nds.subj &lt;- ds %&gt;%\n    select(-sample_id, -Sample_trimester, -Gestationalage_sample) %&gt;%\n    distinct()\n\nselect: dropped 3 variables (sample_id, Sample_trimester, Gestationalage_sample)\n\n\ndistinct: removed 136 rows (71%), 55 rows remaining\n\n\n\nsum(duplicated(ds.subj$subject_id))\n\n[1] 1\n\nds.subj %&gt;%\n    group_by(subject_id) %&gt;%\n    filter(n() &gt; 1)\n\ngroup_by: one grouping variable (subject_id)\n\n\nfilter (grouped): removed 53 rows (96%), 2 rows remaining\n\n\n# A tibble: 2 × 21\n# Groups:   subject_id [1]\n  subject_id strata race  matern…¹ case_…² prepr…³ height prepr…⁴ gravi…⁵ parity\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 SUBJ20         35 W         29.4       1    244.   63.1    44.0       1      0\n2 SUBJ20         35 White     29.4       1    244.   63.1    44.0       1      0\n# … with 11 more variables: gestationalage_delivery &lt;dbl&gt;,\n#   average_SBP_lt20weeks &lt;dbl&gt;, average_DBP_lt20weeks &lt;dbl&gt;,\n#   average_SBP_labor &lt;dbl&gt;, average_DBP_labor &lt;dbl&gt;, smoke_lifetime &lt;chr&gt;,\n#   baby_birthweight &lt;dbl&gt;, baby_sex &lt;chr&gt;, baby_birthweight_centile &lt;dbl&gt;,\n#   baby_SGA &lt;chr&gt;, placental_pathology &lt;chr&gt;, and abbreviated variable names\n#   ¹​maternal_age_delivery, ²​case_control_status, ³​prepregnancy_weight,\n#   ⁴​prepregnancy_BMI, ⁵​gravidity\n\nds.subj &lt;- ds.subj %&gt;%\n    filter(race != \"White\")\n\nfilter: removed one row (2%), 54 rows remaining\n\nsum(duplicated(ds.subj$subject_id))\n\n[1] 0"
  },
  {
    "objectID": "EDA.html#coding",
    "href": "EDA.html#coding",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.6 Coding",
    "text": "13.6 Coding\n\nHow are the data coded?\n\nAre they coded correctly?\nWhich are categorical and which are continuous?\nAre they coded consistently with the data dictionary?\nIs there a data dictionary?\nDo we need to skip rows when reading the data in?\n\n\n\n13.6.1 Recode for understandability\nLet’s recode case_control_status from 0 and 1 into a new PE_status variable coded as control and case.\n\ndd %&gt;%\n    filter(R21.Variable.Name == \"case_control_status\") %&gt;%\n    pull(Variable.Coding)\n\nfilter: removed 26 rows (96%), one row remaining\n\n\n[1] \"0: normotensive control; 1: preeclampsia case\"\n\n\nTask: recode case_control_status from 0 and 1 into a new PE_status variable coded as control and case.\n\n\n\n\n\n\nExpand to see solution\n\n\n\n\n\n\nds.subj$PE_status &lt;- factor(ds.subj$case_control_status)\nlevels(ds.subj$PE_status)\n\n[1] \"0\" \"1\"\n\nlevels(ds.subj$PE_status) &lt;- c(\"control\", \"case\")\nxtabs(~case_control_status + PE_status, data = ds.subj)\n\n                   PE_status\ncase_control_status control case\n                  0      26    0\n                  1       0   28"
  },
  {
    "objectID": "EDA.html#missing-data",
    "href": "EDA.html#missing-data",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.7 Missing data",
    "text": "13.7 Missing data\n\nWhat is the pattern of missing data?\n\nHow are missing data coded?\nIs there a single missing data code?\n\n\nHere we use some plotting commands from the DataExplorer R package.\nhttps://boxuancui.github.io/DataExplorer/index.html\n\nplot_missing(ds.subj)"
  },
  {
    "objectID": "EDA.html#distribution",
    "href": "EDA.html#distribution",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.8 Distribution",
    "text": "13.8 Distribution\n\nWhat is the distribution of each of our phenotypes?\n\nAre data skewed?\nWhat is the range of values?\nIs the range of values realistic?\n\n\n\nplot_bar(ds.subj)\n\n1 columns ignored with more than 50 categories.\nsubject_id: 54 categories\n\n\n\n\n\n\nplot_histogram(ds.subj)\n\n\n\n\n\nplot_qq(ds.subj)"
  },
  {
    "objectID": "EDA.html#variation",
    "href": "EDA.html#variation",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.9 Variation",
    "text": "13.9 Variation\n\nHow do our data vary and co-vary?\n\nDo multiple measures agree with each other?\nAre there sex-specific or age-specific differences?\n\n\n\n13.9.1 Bar plots\n\nplot_bar(ds.subj, by = \"PE_status\")\n\n1 columns ignored with more than 50 categories.\nsubject_id: 54 categories\n\n\n\n\n\n\n\n13.9.2 Box plots\n\nplot_boxplot(ds.subj, by = \"PE_status\")\n\n\n\n\n\n\n\n\n\n13.9.3 QQ plots\n\nplot_qq(ds.subj, by = \"PE_status\")\n\n\n\n\n\n\n\n\n\n13.9.4 Correlation\n\nplot_correlation(ds.subj)\n\n1 features with more than 20 categories ignored!\nsubject_id: 54 categories\n\n\nWarning in cor(x = structure(list(strata = c(29, 39, 29, 36, 40, 39, 40, : the\nstandard deviation is zero\n\n\n\n\n\n\n\n13.9.5 ggpairs from the GGally R package.\nUse ggpairs from the GGally R package.\n\n# Pull out numeric columns\nds1 &lt;- ds.subj[, sapply(ds.subj, is.numeric)]\n\n\nggpairs(ds1[, c(13:15)])\n\n\n\n\nggpairs - color by ggplot2 aes\n\nggpairs(ds.subj, columns = c(15, 17, 19), ggplot2::aes(color = PE_status))\n\n\n\n\n\nggcorr(ds1[, c(13:15)], label = TRUE)"
  },
  {
    "objectID": "EDA.html#dataexplorer",
    "href": "EDA.html#dataexplorer",
    "title": "13  R Exploratory Data Analysis Exercise",
    "section": "13.10 DataExplorer",
    "text": "13.10 DataExplorer\nWe can quickly create a report using the create_report function from the DataExplorer R package\ncreate_report(ds.subj)"
  },
  {
    "objectID": "Basic_Unix_commands.html#acknowledgment-and-license",
    "href": "Basic_Unix_commands.html#acknowledgment-and-license",
    "title": "14  Basic Shell Commands",
    "section": "14.1 Acknowledgment and License",
    "text": "14.1 Acknowledgment and License\nThis chapter is a derivative of the Basic Shell Commands cheat sheet from the DEPRECATED-boot-camps/shell/shell_cheatsheet.md file created by Software Carpentry and is used under the Creative Commons - Attribution license CC BY 3.0\nMinor section numbering and formatting changes were made here.\nThis chapter is licensed under the CC BY 3.0 license by Daniel E. Weeks."
  },
  {
    "objectID": "Basic_Unix_commands.html#shell-basics",
    "href": "Basic_Unix_commands.html#shell-basics",
    "title": "14  Basic Shell Commands",
    "section": "14.2 Shell Basics:",
    "text": "14.2 Shell Basics:\n\n\n\n\n\n\n\nCommand\nDefinition\n\n\n\n\n.\na single period refers to the current directory\n\n\n..\na double period refers to the directory immediately above the current directory\n\n\n~\nrefers to your home directory. Note: this command does NOT work on Windows machines (Mac and Linux are okay)\n\n\ncd ./dirname\nchanges the current directory to the directory dirname\n\n\nls -F\ntells you what files and directories are in the current directory\n\n\npwd\ntells you what directory you are in (pwd stands for print working directory)\n\n\nhistory\nlists previous commands you have entered. history | less lets you page through the list.\n\n\nman cmd\ndisplays the manual page for a command."
  },
  {
    "objectID": "Basic_Unix_commands.html#creating-things",
    "href": "Basic_Unix_commands.html#creating-things",
    "title": "14  Basic Shell Commands",
    "section": "14.3 Creating Things:",
    "text": "14.3 Creating Things:\n\n14.3.1 How to create new files and directories..\n\n\n\n\n\n\n\nCommand\nDefinition\n\n\n\n\nmkdir ./dirname\nmakes a new directory called dirname below the current directory. Note: Windows users will need to use \\ instead of / for the path separator\n\n\nnano filename\nif filename does not exist, nano creates it and opens the nano text editor. If the file exists, nano opens it. Note: (i) You can use a different text editor if you like. In gnome Linux, gedit works really well too. (ii) nano (or gedit) create text files. It doesn’t matter what the file extension is (or if there is one)\n\n\n\n\n\n14.3.2 How to delete files and directories…\n\n14.3.2.1 Remember that deleting is forever. There is NO going back\n\n\n\n\n\n\n\nCommand\nDefinition\n\n\n\n\nrm ./filename\ndeletes a file called filename from the current directory\n\n\nrmdir ./dirname\ndeletes the directory dirname from the current directory. Note: dirname must be empty for rmdir to run.\n\n\n\n\n\n\n14.3.3 How to copy and rename files and directories…\n\n\n\n\n\n\n\nCommand\nDefinition\n\n\n\n\nmv tmp/filename .\nmoves the file filename from the directory tmp to the current directory. Note: (i) the original filename in tmp is deleted. (ii) mv can also be used to rename files (e.g., mv filename newname\n\n\ncp tmp/filename .\ncopies the file filename from the directory tmp to the current directory. Note: (i) the original file is still there"
  },
  {
    "objectID": "Basic_Unix_commands.html#pipes-and-filters",
    "href": "Basic_Unix_commands.html#pipes-and-filters",
    "title": "14  Basic Shell Commands",
    "section": "14.4 Pipes and Filters",
    "text": "14.4 Pipes and Filters\n\n14.4.1 How to use wildcards to match filenames…\nWildcards are a shell feature that makes the command line much more powerful than any GUI file managers. Wildcards are particularly useful when you are looking for directories, files, or file content that can vary along a given dimension. These wildcards can be used with any command that accepts file names or text strings as arguments.\n\n14.4.1.1 Table of commonly used wildcards\n\n\n\n\n\n\n\nWildcard\nMatches\n\n\n\n\n*\nzero or more characters\n\n\n?\nexactly one character\n\n\n[abcde]\nexactly one of the characters listed\n\n\n[a-e]\nexactly one character in the given range\n\n\n[!abcde]\nany character not listed\n\n\n[!a-e]\nany character that is not in the given range\n\n\n{software,carpentry}\nexactly one entire word from the options given\n\n\n\nSee the cheatsheet on regular expressions on the second page of this PDF cheatsheet for more “wildcard” shortcuts.\n\n\n\n14.4.2 How to redirect to a file and get input from a file …\nRedirection operators can be used to redirect the output from a program from the display screen to a file where it is saved (or many other places too, like your printer or to another program where it can be used as input).\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\n&gt;\nwrite stdout to a new file; overwrites any file with that name (e.g., ls *.md &gt; mardkownfiles.txt)\n\n\n&gt;&gt;\nappend stdout to a previously existing file; if the file does not exist, it is created (e.g., ls *.md &gt;&gt; markdownfiles.txt)\n\n\n&lt;\nassigns the information in a file to a variable, loop, etc (e.g., n &lt; markdownfiles.md)\n\n\n\n\n14.4.2.1 How to use the output of one command as the input to another with a pipe…\nA special kind of redirection is called a pipe and is denoted by |.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\n|\nOutput from one command line program can be used as input to another one (e.g. ls *.md | head gives you the first 5 *.md files in your directory)\n\n\n\n\n14.4.2.1.1 Example:\nls *.md | head | sed -i `s/markdown/software/g`\nchanges all the instances of the word markdown to software in the first 5 *.md files in your current directory."
  },
  {
    "objectID": "Basic_Unix_commands.html#how-to-repeat-operations-using-a-loop",
    "href": "Basic_Unix_commands.html#how-to-repeat-operations-using-a-loop",
    "title": "14  Basic Shell Commands",
    "section": "14.5 How to repeat operations using a loop…",
    "text": "14.5 How to repeat operations using a loop…\nLoops assign a value in a list or counter to a variable that takes on a different value each time through the loop. There are 2 primary kinds of loops: for loops and while loops.\n\n14.5.1 For loop\nFor loops loop through variables in a list\nfor varname in list\ndo\n    command1 $varname\n    command2 $varname\ndone\nwhere,\n\nfor, in, do, and done are keywords\nlist contains a list of values separated by spaces. e.g. list can be replaced by 1 2 3 4 5 6 or by Bob Mary Sue Greg. list can also be a variable:\nvarname is assigned a value without using a $ and the value is retrieved using $varname\n\n–\nlist[0]=Sam\nlist[1]=Lynne\nlist[2]=Dhavide\nlist[3]=Trevor\n.\n.\n.\nlist[n]=Mark\nwhich is referenced in the loop by:\nfor varname in ${list[@]}\ndo\n    command1 $varname\n    command2 $varname\ndone\nNote: Bash is zero indexed, so counting always starts at 0, not 1.\n\n\n14.5.2 While Loop\nWhile loops loop through the commands until a condition is met. For example\nCOUNTER=0\nwhile [ ${COUNTER} -lt 10 ]; do\n    command 1\n    command 2\n    COUNTER=`expr ${COUNTER} + 1` \ndone\ncontinues the loop as long as the value in the variable COUNTER is less than 10 (incremented by 1 on each iteration of the loop).\n\nwhile, do, and done are keywords\n\n\n14.5.2.1 Commonly used conditional operators\n\n\n\nOperator\nDefinition\n\n\n\n\n-eq\nis equal to\n\n\n-ne\nis not equal to\n\n\n-gt\ngreater than\n\n\n-ge\ngreater than or equal to\n\n\n-lt\nless than\n\n\n-le\nless than or equal to\n\n\n\nUse man bash or man test to learn about other operators you can use."
  },
  {
    "objectID": "Basic_Unix_commands.html#finding-things",
    "href": "Basic_Unix_commands.html#finding-things",
    "title": "14  Basic Shell Commands",
    "section": "14.6 Finding Things",
    "text": "14.6 Finding Things\n\n14.6.1 How to select lines matching patterns in text files…\nTo find information within files, you use a command called grep.\n\n\n\n\n\n\n\nExample command\nDescription\n\n\n\n\ngrep [options] day haiku.txt\nfinds every instance of the string day in the file haiku.txt and pipes it to standard output\n\n\n\n\n14.6.1.1 Commonly used grep options\n\n\n\n\n\n\n\n\ngrep options\n\n\n\n\n-E\ntells grep you will be using a regular expression. Enclose the regular expression in quotes. Note: the power of grep comes from using regular expressions. Please see the regular expressions sheet for examples\n\n\n-i\nmakes matching case-insensitive\n\n\n-n\nlimits the number of lines that match to the first n matches\n\n\n-v\nshows lines that do not match the pattern (inverts the match)\n\n\n-w\noutputs instances where the pattern is a whole word\n\n\n\n\n\n\n14.6.2 How to find files with certain properties…\nTo find file and directory names, you use a command called find\n\n\n\n\n\n\n\nExample command\nDescription\n\n\n\n\nfind . -type d\nfind recursively descends the directory tree for each path listed to match the expression given in the command line with file or directory names in the search path\n\n\n\n\n14.6.2.1 Commonly used find options\n\n\n\n\n\n\n\n\nfind options\n\n\n\n\n-type [df]\nd lists directories; f lists files\n\n\n-maxdepth n\nfind automatically searches subdirectories. If you don’t want that, specify the number of levels below the working directory you would like to search\n\n\n-mindepth n\nstarts find’s search n levels below the working directory"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "15  Summary",
    "section": "",
    "text": "In summary, this book is a work in progress."
  },
  {
    "objectID": "webR_test.html",
    "href": "webR_test.html",
    "title": "16  WebR - R in the web browser",
    "section": "",
    "text": "This is a WebR-enabled code cell in a Quarto HTML document which works when viewed in a Chrome browser.\nLoading\n  webR...\n\n\n  \n\n\nLink: WebR."
  },
  {
    "objectID": "TechnicalDetails.html#quarto",
    "href": "TechnicalDetails.html#quarto",
    "title": "17  Technical Details",
    "section": "17.1 Quarto",
    "text": "17.1 Quarto\nThis book was build using Quarto.\n\n17.1.1 Callout blocks\nTo hide a solution that then can be clicked to view, we use a .callout-tip collapse=\"true\" callout block.\nHere are some examples from the Quarto documentation:\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCallouts provide a simple way to attract attention, for example, to this warning.\n\n\n\n\n\n\n\n\nThis is Important\n\n\n\nDanger, callouts will really improve your writing.\n\n\n\n\n\n\n\n\nTip With Title\n\n\n\nThis is an example of a callout with a title.\n\n\n\n\n\n\n\n\nExpand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘collapsed’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default.\n\n\n\n\n\n17.1.2 Adding a chapter\nTo add a new chapter to the book, make a Quarto file containing the chapter text and code. It should have only one top-level header at the beginning which will be the title of the chapter.\nThen add it to the list of chapters in the _quarto.yml file."
  },
  {
    "objectID": "TechnicalDetails.html#previewing-the-book",
    "href": "TechnicalDetails.html#previewing-the-book",
    "title": "17  Technical Details",
    "section": "17.2 Previewing the book",
    "text": "17.2 Previewing the book\nType quarto preview in the Terminal window."
  },
  {
    "objectID": "TechnicalDetails.html#deploying-the-book-to-github-pages",
    "href": "TechnicalDetails.html#deploying-the-book-to-github-pages",
    "title": "17  Technical Details",
    "section": "17.3 Deploying the book to GitHub Pages",
    "text": "17.3 Deploying the book to GitHub Pages\nType quarto publish in the Terminal window."
  },
  {
    "objectID": "TechnicalDetails.html#deploying-the-book-to-netlify",
    "href": "TechnicalDetails.html#deploying-the-book-to-netlify",
    "title": "17  Technical Details",
    "section": "17.4 Deploying the book to Netlify",
    "text": "17.4 Deploying the book to Netlify\nType quarto publish netlify in the Terminal window."
  },
  {
    "objectID": "TechnicalDetails.html#webr-r-in-the-browser",
    "href": "TechnicalDetails.html#webr-r-in-the-browser",
    "title": "17  Technical Details",
    "section": "17.5 WebR: R in the browser",
    "text": "17.5 WebR: R in the browser\nThis Quarto book uses this WebR Quarto extension\nhttps://github.com/coatless/quarto-webr\nWebR makes installs a version of R that runs within the browser, and the Quarto extension makes it interactively available in web-r chunks.\nTo get this to work, the _quarto.yml had to be modified.\nWe added a ‘resources’ directive to copy over the java script files, which places them next to the ‘index.html’ file during deployment of the book:\nproject:\n  type: book\n  resources: \n    - \"webr-serviceworker.js\"\n    - \"webr-worker.js\" \nWe also enabled the webr filter:\nfilters:\n    - webr"
  }
]